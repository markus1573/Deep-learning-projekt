{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4f85a-37b5-472e-8782-a5df13c5d601",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec1af4-1d61-46ef-90b9-b972129d09a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeb867f-c38e-4e5c-ab89-a7e747ead472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d87cd-410b-44ef-ac34-560022867208",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#torch.backends.cudnn.enabled = False\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Downloading MNIST again :) Training (60k) and test(5k) + val(5k) split\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data',\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_dataset = datasets.MNIST('./mnist_data',\n",
    "                               download=True,\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "val_dataset, test_dataset = random_split(test_dataset, [val_size, test_size])\n",
    "\n",
    "# Test set to compare with DDPM paper\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Validation set so we can keep track of approximated FID score while training\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ae1fca-cff3-4b53-86d1-65c59740a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up alpha_bar for training and test so alpha_bar_t = alpha_bar[t]\n",
    "T = 1000\n",
    "beta_start, beta_end = [1e-4, 2e-02]\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1-beta\n",
    "alpha_bar = alpha.clone()\n",
    "for e in range(T-1):\n",
    "    alpha_bar[e+1] *= alpha_bar[e]\n",
    "\n",
    "alpha = alpha.view((1000, 1, 1, 1)).to(device)\n",
    "beta = beta.view((1000, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((1000, 1, 1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fe879-ee13-4434-9a0d-de015ddd4c2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c671dbab-ffe9-4fe5-841a-80042e7593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        channels = [32, 64, 128, 256]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(2, channels[0], kernel_size=3, padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 32, 14, 14)\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=3, padding=1),  # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 64, 7, 7)\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, padding=1),  # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2, padding=1),  # (batchsize, 128, 4, 4)\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=3, padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.tconvs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=0),   # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[2]*2, channels[1], kernel_size=3,\n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[1]*2, channels[0], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels[0]*2,channels[0],kernel_size=3,padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(channels[0],1,kernel_size=1) # (batchsize, 1, 28, 28)\n",
    "            )      \n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_trans = torch.cat((x, t), dim=-3)\n",
    "        signal = x_trans\n",
    "        signals = []\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # print(f\"conv {i}\")\n",
    "            signal = conv(signal)\n",
    "            # print(signal.shape)\n",
    "            if i < len(conv):\n",
    "                signals.append(signal)\n",
    "        \n",
    "        for i, tconv in enumerate(self.tconvs):\n",
    "            # print(f\"tconv {i}\")\n",
    "            # print(f\"signal shape: {signal.shape}\")\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04a5df-da69-407e-9285-90de11992cef",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8403ab0-aea6-492a-98b9-31ab55064c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "epochs = 10\n",
    "model = UNET()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc7e14a-63cd-4432-8f07-43fd00841fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 100), loss: 78578336.253\n",
      "(0, 200), loss: 1145486.697\n",
      "(0, 300), loss: 1053935.149\n",
      "(0, 400), loss: 971328.878\n",
      "(0, 500), loss: 890939.700\n",
      "(0, 600), loss: 808739.320\n",
      "(0, 700), loss: 739154.519\n",
      "(0, 800), loss: 674102.320\n",
      "(0, 900), loss: 604442.711\n",
      "(0, 1000), loss: 551610.452\n",
      "(0, 1100), loss: 499652.636\n",
      "(0, 1200), loss: 452129.303\n",
      "(0, 1300), loss: 393777.650\n",
      "(0, 1400), loss: 375523.385\n",
      "(0, 1500), loss: 336397.442\n",
      "(0, 1600), loss: 288248.737\n",
      "(0, 1700), loss: 268627.358\n",
      "(0, 1800), loss: 253391.202\n",
      "(0, 1900), loss: 251286.664\n",
      "(0, 2000), loss: 226346.861\n",
      "(0, 2100), loss: 216790.087\n",
      "(0, 2200), loss: 206215.364\n",
      "(0, 2300), loss: 198554.569\n",
      "(0, 2400), loss: 205182.737\n",
      "(0, 2500), loss: 206298.417\n",
      "(0, 2600), loss: 185512.696\n",
      "(0, 2700), loss: 185430.950\n",
      "(0, 2800), loss: 214630.608\n",
      "(0, 2900), loss: 10130534.897\n",
      "(0, 3000), loss: 354766.156\n",
      "(0, 3100), loss: 215164.619\n",
      "(0, 3200), loss: 195457.508\n",
      "(0, 3300), loss: 194991.698\n",
      "(0, 3400), loss: 181711.698\n",
      "(0, 3500), loss: 185008.519\n",
      "(0, 3600), loss: 187319.186\n",
      "(0, 3700), loss: 177285.123\n",
      "(1, 100), loss: 255741.354\n",
      "(1, 200), loss: 176216.093\n",
      "(1, 300), loss: 172128.232\n",
      "(1, 400), loss: 142133.132\n",
      "(1, 500), loss: 124781.593\n",
      "(1, 600), loss: 114864.932\n",
      "(1, 700), loss: 96792.681\n",
      "(1, 800), loss: 75724.305\n",
      "(1, 900), loss: 81745.714\n",
      "(1, 1000), loss: 73345.014\n",
      "(1, 1100), loss: 73417.004\n",
      "(1, 1200), loss: 81713.743\n",
      "(1, 1300), loss: 59561.022\n",
      "(1, 1400), loss: 64347.013\n",
      "(1, 1500), loss: 62203.161\n",
      "(1, 1600), loss: 67120.051\n",
      "(1, 1700), loss: 63011.456\n",
      "(1, 1800), loss: 65105.994\n",
      "(1, 1900), loss: 61528.100\n",
      "(1, 2000), loss: 55610.810\n",
      "(1, 2100), loss: 60854.467\n",
      "(1, 2200), loss: 60070.070\n",
      "(1, 2300), loss: 52406.023\n",
      "(1, 2400), loss: 50341.034\n",
      "(1, 2500), loss: 58241.258\n",
      "(1, 2600), loss: 69449.036\n",
      "(1, 2700), loss: 52120.785\n",
      "(1, 2800), loss: 185130.007\n",
      "(1, 2900), loss: 181517.999\n",
      "(1, 3000), loss: 58951.504\n",
      "(1, 3100), loss: 56834.339\n",
      "(1, 3200), loss: 59172.050\n",
      "(1, 3300), loss: 56537.576\n",
      "(1, 3400), loss: 64798.532\n",
      "(1, 3500), loss: 54215.728\n",
      "(1, 3600), loss: 58501.220\n",
      "(1, 3700), loss: 1349547.247\n",
      "(2, 100), loss: 450287.657\n",
      "(2, 200), loss: 132602.026\n",
      "(2, 300), loss: 84222.821\n",
      "(2, 400), loss: 66316.727\n",
      "(2, 500), loss: 61210.973\n",
      "(2, 600), loss: 57601.124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      3\u001b[0m         x0, _ \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      4\u001b[0m         x0 \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\queues.py:117\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 117\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recv_bytes()\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[1;34m(self, maxlength)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recv_bytes(maxlength)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\multiprocessing\\connection.py:317\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    315\u001b[0m bsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(maxsize, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     ov, err \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mReadFile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle, bsize,\n\u001b[0;32m    318\u001b[0m                                 overlapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for e, data in enumerate(train_loader):\n",
    "        x0, _ = data\n",
    "        x0 = x0.to(device)\n",
    "        t = torch.randint(1, T+1, (batch_size,)).to(device)\n",
    "        eps = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        # print(eps.shape)\n",
    "        # print(x0.shape)\n",
    "        loss = criterion(eps, model(torch.sqrt(alpha_bar[t-1]) * x0 + \n",
    "                                    torch.sqrt(1 - alpha_bar[t-1]) * eps, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 28, 28)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if e % 100 == 99:\n",
    "            print(f'{epoch, e+1}, loss: {running_loss:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    if epoch % 5 == 4:\n",
    "        torch.save(model.state_dict(), f\"DDPM_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a74a6-6786-43c8-9b7b-569eb01df2f2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16cd8cdb-77e0-4881-ace7-79d6da4848ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (tconvs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f69f28-7031-48bc-96d4-85b61ba8d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000)\n",
      "tensor(999)\n",
      "tensor(998)\n",
      "tensor(997)\n",
      "tensor(996)\n",
      "tensor(995)\n",
      "tensor(994)\n",
      "tensor(993)\n",
      "tensor(992)\n",
      "tensor(991)\n",
      "tensor(990)\n",
      "tensor(989)\n",
      "tensor(988)\n",
      "tensor(987)\n",
      "tensor(986)\n",
      "tensor(985)\n",
      "tensor(984)\n",
      "tensor(983)\n",
      "tensor(982)\n",
      "tensor(981)\n",
      "tensor(980)\n",
      "tensor(979)\n",
      "tensor(978)\n",
      "tensor(977)\n",
      "tensor(976)\n",
      "tensor(975)\n",
      "tensor(974)\n",
      "tensor(973)\n",
      "tensor(972)\n",
      "tensor(971)\n",
      "tensor(970)\n",
      "tensor(969)\n",
      "tensor(968)\n",
      "tensor(967)\n",
      "tensor(966)\n",
      "tensor(965)\n",
      "tensor(964)\n",
      "tensor(963)\n",
      "tensor(962)\n",
      "tensor(961)\n",
      "tensor(960)\n",
      "tensor(959)\n",
      "tensor(958)\n",
      "tensor(957)\n",
      "tensor(956)\n",
      "tensor(955)\n",
      "tensor(954)\n",
      "tensor(953)\n",
      "tensor(952)\n",
      "tensor(951)\n",
      "tensor(950)\n",
      "tensor(949)\n",
      "tensor(948)\n",
      "tensor(947)\n",
      "tensor(946)\n",
      "tensor(945)\n",
      "tensor(944)\n",
      "tensor(943)\n",
      "tensor(942)\n",
      "tensor(941)\n",
      "tensor(940)\n",
      "tensor(939)\n",
      "tensor(938)\n",
      "tensor(937)\n",
      "tensor(936)\n",
      "tensor(935)\n",
      "tensor(934)\n",
      "tensor(933)\n",
      "tensor(932)\n",
      "tensor(931)\n",
      "tensor(930)\n",
      "tensor(929)\n",
      "tensor(928)\n",
      "tensor(927)\n",
      "tensor(926)\n",
      "tensor(925)\n",
      "tensor(924)\n",
      "tensor(923)\n",
      "tensor(922)\n",
      "tensor(921)\n",
      "tensor(920)\n",
      "tensor(919)\n",
      "tensor(918)\n",
      "tensor(917)\n",
      "tensor(916)\n",
      "tensor(915)\n",
      "tensor(914)\n",
      "tensor(913)\n",
      "tensor(912)\n",
      "tensor(911)\n",
      "tensor(910)\n",
      "tensor(909)\n",
      "tensor(908)\n",
      "tensor(907)\n",
      "tensor(906)\n",
      "tensor(905)\n",
      "tensor(904)\n",
      "tensor(903)\n",
      "tensor(902)\n",
      "tensor(901)\n",
      "tensor(900)\n",
      "tensor(899)\n",
      "tensor(898)\n",
      "tensor(897)\n",
      "tensor(896)\n",
      "tensor(895)\n",
      "tensor(894)\n",
      "tensor(893)\n",
      "tensor(892)\n",
      "tensor(891)\n",
      "tensor(890)\n",
      "tensor(889)\n",
      "tensor(888)\n",
      "tensor(887)\n",
      "tensor(886)\n",
      "tensor(885)\n",
      "tensor(884)\n",
      "tensor(883)\n",
      "tensor(882)\n",
      "tensor(881)\n",
      "tensor(880)\n",
      "tensor(879)\n",
      "tensor(878)\n",
      "tensor(877)\n",
      "tensor(876)\n",
      "tensor(875)\n",
      "tensor(874)\n",
      "tensor(873)\n",
      "tensor(872)\n",
      "tensor(871)\n",
      "tensor(870)\n",
      "tensor(869)\n",
      "tensor(868)\n",
      "tensor(867)\n",
      "tensor(866)\n",
      "tensor(865)\n",
      "tensor(864)\n",
      "tensor(863)\n",
      "tensor(862)\n",
      "tensor(861)\n",
      "tensor(860)\n",
      "tensor(859)\n",
      "tensor(858)\n",
      "tensor(857)\n",
      "tensor(856)\n",
      "tensor(855)\n",
      "tensor(854)\n",
      "tensor(853)\n",
      "tensor(852)\n",
      "tensor(851)\n",
      "tensor(850)\n",
      "tensor(849)\n",
      "tensor(848)\n",
      "tensor(847)\n",
      "tensor(846)\n",
      "tensor(845)\n",
      "tensor(844)\n",
      "tensor(843)\n",
      "tensor(842)\n",
      "tensor(841)\n",
      "tensor(840)\n",
      "tensor(839)\n",
      "tensor(838)\n",
      "tensor(837)\n",
      "tensor(836)\n",
      "tensor(835)\n",
      "tensor(834)\n",
      "tensor(833)\n",
      "tensor(832)\n",
      "tensor(831)\n",
      "tensor(830)\n",
      "tensor(829)\n",
      "tensor(828)\n",
      "tensor(827)\n",
      "tensor(826)\n",
      "tensor(825)\n",
      "tensor(824)\n",
      "tensor(823)\n",
      "tensor(822)\n",
      "tensor(821)\n",
      "tensor(820)\n",
      "tensor(819)\n",
      "tensor(818)\n",
      "tensor(817)\n",
      "tensor(816)\n",
      "tensor(815)\n",
      "tensor(814)\n",
      "tensor(813)\n",
      "tensor(812)\n",
      "tensor(811)\n",
      "tensor(810)\n",
      "tensor(809)\n",
      "tensor(808)\n",
      "tensor(807)\n",
      "tensor(806)\n",
      "tensor(805)\n",
      "tensor(804)\n",
      "tensor(803)\n",
      "tensor(802)\n",
      "tensor(801)\n",
      "tensor(800)\n",
      "tensor(799)\n",
      "tensor(798)\n",
      "tensor(797)\n",
      "tensor(796)\n",
      "tensor(795)\n",
      "tensor(794)\n",
      "tensor(793)\n",
      "tensor(792)\n",
      "tensor(791)\n",
      "tensor(790)\n",
      "tensor(789)\n",
      "tensor(788)\n",
      "tensor(787)\n",
      "tensor(786)\n",
      "tensor(785)\n",
      "tensor(784)\n",
      "tensor(783)\n",
      "tensor(782)\n",
      "tensor(781)\n",
      "tensor(780)\n",
      "tensor(779)\n",
      "tensor(778)\n",
      "tensor(777)\n",
      "tensor(776)\n",
      "tensor(775)\n",
      "tensor(774)\n",
      "tensor(773)\n",
      "tensor(772)\n",
      "tensor(771)\n",
      "tensor(770)\n",
      "tensor(769)\n",
      "tensor(768)\n",
      "tensor(767)\n",
      "tensor(766)\n",
      "tensor(765)\n",
      "tensor(764)\n",
      "tensor(763)\n",
      "tensor(762)\n",
      "tensor(761)\n",
      "tensor(760)\n",
      "tensor(759)\n",
      "tensor(758)\n",
      "tensor(757)\n",
      "tensor(756)\n",
      "tensor(755)\n",
      "tensor(754)\n",
      "tensor(753)\n",
      "tensor(752)\n",
      "tensor(751)\n",
      "tensor(750)\n",
      "tensor(749)\n",
      "tensor(748)\n",
      "tensor(747)\n",
      "tensor(746)\n",
      "tensor(745)\n",
      "tensor(744)\n",
      "tensor(743)\n",
      "tensor(742)\n",
      "tensor(741)\n",
      "tensor(740)\n",
      "tensor(739)\n",
      "tensor(738)\n",
      "tensor(737)\n",
      "tensor(736)\n",
      "tensor(735)\n",
      "tensor(734)\n",
      "tensor(733)\n",
      "tensor(732)\n",
      "tensor(731)\n",
      "tensor(730)\n",
      "tensor(729)\n",
      "tensor(728)\n",
      "tensor(727)\n",
      "tensor(726)\n",
      "tensor(725)\n",
      "tensor(724)\n",
      "tensor(723)\n",
      "tensor(722)\n",
      "tensor(721)\n",
      "tensor(720)\n",
      "tensor(719)\n",
      "tensor(718)\n",
      "tensor(717)\n",
      "tensor(716)\n",
      "tensor(715)\n",
      "tensor(714)\n",
      "tensor(713)\n",
      "tensor(712)\n",
      "tensor(711)\n",
      "tensor(710)\n",
      "tensor(709)\n",
      "tensor(708)\n",
      "tensor(707)\n",
      "tensor(706)\n",
      "tensor(705)\n",
      "tensor(704)\n",
      "tensor(703)\n",
      "tensor(702)\n",
      "tensor(701)\n",
      "tensor(700)\n",
      "tensor(699)\n",
      "tensor(698)\n",
      "tensor(697)\n",
      "tensor(696)\n",
      "tensor(695)\n",
      "tensor(694)\n",
      "tensor(693)\n",
      "tensor(692)\n",
      "tensor(691)\n",
      "tensor(690)\n",
      "tensor(689)\n",
      "tensor(688)\n",
      "tensor(687)\n",
      "tensor(686)\n",
      "tensor(685)\n",
      "tensor(684)\n",
      "tensor(683)\n",
      "tensor(682)\n",
      "tensor(681)\n",
      "tensor(680)\n",
      "tensor(679)\n",
      "tensor(678)\n",
      "tensor(677)\n",
      "tensor(676)\n",
      "tensor(675)\n",
      "tensor(674)\n",
      "tensor(673)\n",
      "tensor(672)\n",
      "tensor(671)\n",
      "tensor(670)\n",
      "tensor(669)\n",
      "tensor(668)\n",
      "tensor(667)\n",
      "tensor(666)\n",
      "tensor(665)\n",
      "tensor(664)\n",
      "tensor(663)\n",
      "tensor(662)\n",
      "tensor(661)\n",
      "tensor(660)\n",
      "tensor(659)\n",
      "tensor(658)\n",
      "tensor(657)\n",
      "tensor(656)\n",
      "tensor(655)\n",
      "tensor(654)\n",
      "tensor(653)\n",
      "tensor(652)\n",
      "tensor(651)\n",
      "tensor(650)\n",
      "tensor(649)\n",
      "tensor(648)\n",
      "tensor(647)\n",
      "tensor(646)\n",
      "tensor(645)\n",
      "tensor(644)\n",
      "tensor(643)\n",
      "tensor(642)\n",
      "tensor(641)\n",
      "tensor(640)\n",
      "tensor(639)\n",
      "tensor(638)\n",
      "tensor(637)\n",
      "tensor(636)\n",
      "tensor(635)\n",
      "tensor(634)\n",
      "tensor(633)\n",
      "tensor(632)\n",
      "tensor(631)\n",
      "tensor(630)\n",
      "tensor(629)\n",
      "tensor(628)\n",
      "tensor(627)\n",
      "tensor(626)\n",
      "tensor(625)\n",
      "tensor(624)\n",
      "tensor(623)\n",
      "tensor(622)\n",
      "tensor(621)\n",
      "tensor(620)\n",
      "tensor(619)\n",
      "tensor(618)\n",
      "tensor(617)\n",
      "tensor(616)\n",
      "tensor(615)\n",
      "tensor(614)\n",
      "tensor(613)\n",
      "tensor(612)\n",
      "tensor(611)\n",
      "tensor(610)\n",
      "tensor(609)\n",
      "tensor(608)\n",
      "tensor(607)\n",
      "tensor(606)\n",
      "tensor(605)\n",
      "tensor(604)\n",
      "tensor(603)\n",
      "tensor(602)\n",
      "tensor(601)\n",
      "tensor(600)\n",
      "tensor(599)\n",
      "tensor(598)\n",
      "tensor(597)\n",
      "tensor(596)\n",
      "tensor(595)\n",
      "tensor(594)\n",
      "tensor(593)\n",
      "tensor(592)\n",
      "tensor(591)\n",
      "tensor(590)\n",
      "tensor(589)\n",
      "tensor(588)\n",
      "tensor(587)\n",
      "tensor(586)\n",
      "tensor(585)\n",
      "tensor(584)\n",
      "tensor(583)\n",
      "tensor(582)\n",
      "tensor(581)\n",
      "tensor(580)\n",
      "tensor(579)\n",
      "tensor(578)\n",
      "tensor(577)\n",
      "tensor(576)\n",
      "tensor(575)\n",
      "tensor(574)\n",
      "tensor(573)\n",
      "tensor(572)\n",
      "tensor(571)\n",
      "tensor(570)\n",
      "tensor(569)\n",
      "tensor(568)\n",
      "tensor(567)\n",
      "tensor(566)\n",
      "tensor(565)\n",
      "tensor(564)\n",
      "tensor(563)\n",
      "tensor(562)\n",
      "tensor(561)\n",
      "tensor(560)\n",
      "tensor(559)\n",
      "tensor(558)\n",
      "tensor(557)\n",
      "tensor(556)\n",
      "tensor(555)\n",
      "tensor(554)\n",
      "tensor(553)\n",
      "tensor(552)\n",
      "tensor(551)\n",
      "tensor(550)\n",
      "tensor(549)\n",
      "tensor(548)\n",
      "tensor(547)\n",
      "tensor(546)\n",
      "tensor(545)\n",
      "tensor(544)\n",
      "tensor(543)\n",
      "tensor(542)\n",
      "tensor(541)\n",
      "tensor(540)\n",
      "tensor(539)\n",
      "tensor(538)\n",
      "tensor(537)\n",
      "tensor(536)\n",
      "tensor(535)\n",
      "tensor(534)\n",
      "tensor(533)\n",
      "tensor(532)\n",
      "tensor(531)\n",
      "tensor(530)\n",
      "tensor(529)\n",
      "tensor(528)\n",
      "tensor(527)\n",
      "tensor(526)\n",
      "tensor(525)\n",
      "tensor(524)\n",
      "tensor(523)\n",
      "tensor(522)\n",
      "tensor(521)\n",
      "tensor(520)\n",
      "tensor(519)\n",
      "tensor(518)\n",
      "tensor(517)\n",
      "tensor(516)\n",
      "tensor(515)\n",
      "tensor(514)\n",
      "tensor(513)\n",
      "tensor(512)\n",
      "tensor(511)\n",
      "tensor(510)\n",
      "tensor(509)\n",
      "tensor(508)\n",
      "tensor(507)\n",
      "tensor(506)\n",
      "tensor(505)\n",
      "tensor(504)\n",
      "tensor(503)\n",
      "tensor(502)\n",
      "tensor(501)\n",
      "tensor(500)\n",
      "tensor(499)\n",
      "tensor(498)\n",
      "tensor(497)\n",
      "tensor(496)\n",
      "tensor(495)\n",
      "tensor(494)\n",
      "tensor(493)\n",
      "tensor(492)\n",
      "tensor(491)\n",
      "tensor(490)\n",
      "tensor(489)\n",
      "tensor(488)\n",
      "tensor(487)\n",
      "tensor(486)\n",
      "tensor(485)\n",
      "tensor(484)\n",
      "tensor(483)\n",
      "tensor(482)\n",
      "tensor(481)\n",
      "tensor(480)\n",
      "tensor(479)\n",
      "tensor(478)\n",
      "tensor(477)\n",
      "tensor(476)\n",
      "tensor(475)\n",
      "tensor(474)\n",
      "tensor(473)\n",
      "tensor(472)\n",
      "tensor(471)\n",
      "tensor(470)\n",
      "tensor(469)\n",
      "tensor(468)\n",
      "tensor(467)\n",
      "tensor(466)\n",
      "tensor(465)\n",
      "tensor(464)\n",
      "tensor(463)\n",
      "tensor(462)\n",
      "tensor(461)\n",
      "tensor(460)\n",
      "tensor(459)\n",
      "tensor(458)\n",
      "tensor(457)\n",
      "tensor(456)\n",
      "tensor(455)\n",
      "tensor(454)\n",
      "tensor(453)\n",
      "tensor(452)\n",
      "tensor(451)\n",
      "tensor(450)\n",
      "tensor(449)\n",
      "tensor(448)\n",
      "tensor(447)\n",
      "tensor(446)\n",
      "tensor(445)\n",
      "tensor(444)\n",
      "tensor(443)\n",
      "tensor(442)\n",
      "tensor(441)\n",
      "tensor(440)\n",
      "tensor(439)\n",
      "tensor(438)\n",
      "tensor(437)\n",
      "tensor(436)\n",
      "tensor(435)\n",
      "tensor(434)\n",
      "tensor(433)\n",
      "tensor(432)\n",
      "tensor(431)\n",
      "tensor(430)\n",
      "tensor(429)\n",
      "tensor(428)\n",
      "tensor(427)\n",
      "tensor(426)\n",
      "tensor(425)\n",
      "tensor(424)\n",
      "tensor(423)\n",
      "tensor(422)\n",
      "tensor(421)\n",
      "tensor(420)\n",
      "tensor(419)\n",
      "tensor(418)\n",
      "tensor(417)\n",
      "tensor(416)\n",
      "tensor(415)\n",
      "tensor(414)\n",
      "tensor(413)\n",
      "tensor(412)\n",
      "tensor(411)\n",
      "tensor(410)\n",
      "tensor(409)\n",
      "tensor(408)\n",
      "tensor(407)\n",
      "tensor(406)\n",
      "tensor(405)\n",
      "tensor(404)\n",
      "tensor(403)\n",
      "tensor(402)\n",
      "tensor(401)\n",
      "tensor(400)\n",
      "tensor(399)\n",
      "tensor(398)\n",
      "tensor(397)\n",
      "tensor(396)\n",
      "tensor(395)\n",
      "tensor(394)\n",
      "tensor(393)\n",
      "tensor(392)\n",
      "tensor(391)\n",
      "tensor(390)\n",
      "tensor(389)\n",
      "tensor(388)\n",
      "tensor(387)\n",
      "tensor(386)\n",
      "tensor(385)\n",
      "tensor(384)\n",
      "tensor(383)\n",
      "tensor(382)\n",
      "tensor(381)\n",
      "tensor(380)\n",
      "tensor(379)\n",
      "tensor(378)\n",
      "tensor(377)\n",
      "tensor(376)\n",
      "tensor(375)\n",
      "tensor(374)\n",
      "tensor(373)\n",
      "tensor(372)\n",
      "tensor(371)\n",
      "tensor(370)\n",
      "tensor(369)\n",
      "tensor(368)\n",
      "tensor(367)\n",
      "tensor(366)\n",
      "tensor(365)\n",
      "tensor(364)\n",
      "tensor(363)\n",
      "tensor(362)\n",
      "tensor(361)\n",
      "tensor(360)\n",
      "tensor(359)\n",
      "tensor(358)\n",
      "tensor(357)\n",
      "tensor(356)\n",
      "tensor(355)\n",
      "tensor(354)\n",
      "tensor(353)\n",
      "tensor(352)\n",
      "tensor(351)\n",
      "tensor(350)\n",
      "tensor(349)\n",
      "tensor(348)\n",
      "tensor(347)\n",
      "tensor(346)\n",
      "tensor(345)\n",
      "tensor(344)\n",
      "tensor(343)\n",
      "tensor(342)\n",
      "tensor(341)\n",
      "tensor(340)\n",
      "tensor(339)\n",
      "tensor(338)\n",
      "tensor(337)\n",
      "tensor(336)\n",
      "tensor(335)\n",
      "tensor(334)\n",
      "tensor(333)\n",
      "tensor(332)\n",
      "tensor(331)\n",
      "tensor(330)\n",
      "tensor(329)\n",
      "tensor(328)\n",
      "tensor(327)\n",
      "tensor(326)\n",
      "tensor(325)\n",
      "tensor(324)\n",
      "tensor(323)\n",
      "tensor(322)\n",
      "tensor(321)\n",
      "tensor(320)\n",
      "tensor(319)\n",
      "tensor(318)\n",
      "tensor(317)\n",
      "tensor(316)\n",
      "tensor(315)\n",
      "tensor(314)\n",
      "tensor(313)\n",
      "tensor(312)\n",
      "tensor(311)\n",
      "tensor(310)\n",
      "tensor(309)\n",
      "tensor(308)\n",
      "tensor(307)\n",
      "tensor(306)\n",
      "tensor(305)\n",
      "tensor(304)\n",
      "tensor(303)\n",
      "tensor(302)\n",
      "tensor(301)\n",
      "tensor(300)\n",
      "tensor(299)\n",
      "tensor(298)\n",
      "tensor(297)\n",
      "tensor(296)\n",
      "tensor(295)\n",
      "tensor(294)\n",
      "tensor(293)\n",
      "tensor(292)\n",
      "tensor(291)\n",
      "tensor(290)\n",
      "tensor(289)\n",
      "tensor(288)\n",
      "tensor(287)\n",
      "tensor(286)\n",
      "tensor(285)\n",
      "tensor(284)\n",
      "tensor(283)\n",
      "tensor(282)\n",
      "tensor(281)\n",
      "tensor(280)\n",
      "tensor(279)\n",
      "tensor(278)\n",
      "tensor(277)\n",
      "tensor(276)\n",
      "tensor(275)\n",
      "tensor(274)\n",
      "tensor(273)\n",
      "tensor(272)\n",
      "tensor(271)\n",
      "tensor(270)\n",
      "tensor(269)\n",
      "tensor(268)\n",
      "tensor(267)\n",
      "tensor(266)\n",
      "tensor(265)\n",
      "tensor(264)\n",
      "tensor(263)\n",
      "tensor(262)\n",
      "tensor(261)\n",
      "tensor(260)\n",
      "tensor(259)\n",
      "tensor(258)\n",
      "tensor(257)\n",
      "tensor(256)\n",
      "tensor(255)\n",
      "tensor(254)\n",
      "tensor(253)\n",
      "tensor(252)\n",
      "tensor(251)\n",
      "tensor(250)\n",
      "tensor(249)\n",
      "tensor(248)\n",
      "tensor(247)\n",
      "tensor(246)\n",
      "tensor(245)\n",
      "tensor(244)\n",
      "tensor(243)\n",
      "tensor(242)\n",
      "tensor(241)\n",
      "tensor(240)\n",
      "tensor(239)\n",
      "tensor(238)\n",
      "tensor(237)\n",
      "tensor(236)\n",
      "tensor(235)\n",
      "tensor(234)\n",
      "tensor(233)\n",
      "tensor(232)\n",
      "tensor(231)\n",
      "tensor(230)\n",
      "tensor(229)\n",
      "tensor(228)\n",
      "tensor(227)\n",
      "tensor(226)\n",
      "tensor(225)\n",
      "tensor(224)\n",
      "tensor(223)\n",
      "tensor(222)\n",
      "tensor(221)\n",
      "tensor(220)\n",
      "tensor(219)\n",
      "tensor(218)\n",
      "tensor(217)\n",
      "tensor(216)\n",
      "tensor(215)\n",
      "tensor(214)\n",
      "tensor(213)\n",
      "tensor(212)\n",
      "tensor(211)\n",
      "tensor(210)\n",
      "tensor(209)\n",
      "tensor(208)\n",
      "tensor(207)\n",
      "tensor(206)\n",
      "tensor(205)\n",
      "tensor(204)\n",
      "tensor(203)\n",
      "tensor(202)\n",
      "tensor(201)\n",
      "tensor(200)\n",
      "tensor(199)\n",
      "tensor(198)\n",
      "tensor(197)\n",
      "tensor(196)\n",
      "tensor(195)\n",
      "tensor(194)\n",
      "tensor(193)\n",
      "tensor(192)\n",
      "tensor(191)\n",
      "tensor(190)\n",
      "tensor(189)\n",
      "tensor(188)\n",
      "tensor(187)\n",
      "tensor(186)\n",
      "tensor(185)\n",
      "tensor(184)\n",
      "tensor(183)\n",
      "tensor(182)\n",
      "tensor(181)\n",
      "tensor(180)\n",
      "tensor(179)\n",
      "tensor(178)\n",
      "tensor(177)\n",
      "tensor(176)\n",
      "tensor(175)\n",
      "tensor(174)\n",
      "tensor(173)\n",
      "tensor(172)\n",
      "tensor(171)\n",
      "tensor(170)\n",
      "tensor(169)\n",
      "tensor(168)\n",
      "tensor(167)\n",
      "tensor(166)\n",
      "tensor(165)\n",
      "tensor(164)\n",
      "tensor(163)\n",
      "tensor(162)\n",
      "tensor(161)\n",
      "tensor(160)\n",
      "tensor(159)\n",
      "tensor(158)\n",
      "tensor(157)\n",
      "tensor(156)\n",
      "tensor(155)\n",
      "tensor(154)\n",
      "tensor(153)\n",
      "tensor(152)\n",
      "tensor(151)\n",
      "tensor(150)\n",
      "tensor(149)\n",
      "tensor(148)\n",
      "tensor(147)\n",
      "tensor(146)\n",
      "tensor(145)\n",
      "tensor(144)\n",
      "tensor(143)\n",
      "tensor(142)\n",
      "tensor(141)\n",
      "tensor(140)\n",
      "tensor(139)\n",
      "tensor(138)\n",
      "tensor(137)\n",
      "tensor(136)\n",
      "tensor(135)\n",
      "tensor(134)\n",
      "tensor(133)\n",
      "tensor(132)\n",
      "tensor(131)\n",
      "tensor(130)\n",
      "tensor(129)\n",
      "tensor(128)\n",
      "tensor(127)\n",
      "tensor(126)\n",
      "tensor(125)\n",
      "tensor(124)\n",
      "tensor(123)\n",
      "tensor(122)\n",
      "tensor(121)\n",
      "tensor(120)\n",
      "tensor(119)\n",
      "tensor(118)\n",
      "tensor(117)\n",
      "tensor(116)\n",
      "tensor(115)\n",
      "tensor(114)\n",
      "tensor(113)\n",
      "tensor(112)\n",
      "tensor(111)\n",
      "tensor(110)\n",
      "tensor(109)\n",
      "tensor(108)\n",
      "tensor(107)\n",
      "tensor(106)\n",
      "tensor(105)\n",
      "tensor(104)\n",
      "tensor(103)\n",
      "tensor(102)\n",
      "tensor(101)\n",
      "tensor(100)\n",
      "tensor(99)\n",
      "tensor(98)\n",
      "tensor(97)\n",
      "tensor(96)\n",
      "tensor(95)\n",
      "tensor(94)\n",
      "tensor(93)\n",
      "tensor(92)\n",
      "tensor(91)\n",
      "tensor(90)\n",
      "tensor(89)\n",
      "tensor(88)\n",
      "tensor(87)\n",
      "tensor(86)\n",
      "tensor(85)\n",
      "tensor(84)\n",
      "tensor(83)\n",
      "tensor(82)\n",
      "tensor(81)\n",
      "tensor(80)\n",
      "tensor(79)\n",
      "tensor(78)\n",
      "tensor(77)\n",
      "tensor(76)\n",
      "tensor(75)\n",
      "tensor(74)\n",
      "tensor(73)\n",
      "tensor(72)\n",
      "tensor(71)\n",
      "tensor(70)\n",
      "tensor(69)\n",
      "tensor(68)\n",
      "tensor(67)\n",
      "tensor(66)\n",
      "tensor(65)\n",
      "tensor(64)\n",
      "tensor(63)\n",
      "tensor(62)\n",
      "tensor(61)\n",
      "tensor(60)\n",
      "tensor(59)\n",
      "tensor(58)\n",
      "tensor(57)\n",
      "tensor(56)\n",
      "tensor(55)\n",
      "tensor(54)\n",
      "tensor(53)\n",
      "tensor(52)\n",
      "tensor(51)\n",
      "tensor(50)\n",
      "tensor(49)\n",
      "tensor(48)\n",
      "tensor(47)\n",
      "tensor(46)\n",
      "tensor(45)\n",
      "tensor(44)\n",
      "tensor(43)\n",
      "tensor(42)\n",
      "tensor(41)\n",
      "tensor(40)\n",
      "tensor(39)\n",
      "tensor(38)\n",
      "tensor(37)\n",
      "tensor(36)\n",
      "tensor(35)\n",
      "tensor(34)\n",
      "tensor(33)\n",
      "tensor(32)\n",
      "tensor(31)\n",
      "tensor(30)\n",
      "tensor(29)\n",
      "tensor(28)\n",
      "tensor(27)\n",
      "tensor(26)\n",
      "tensor(25)\n",
      "tensor(24)\n",
      "tensor(23)\n",
      "tensor(22)\n",
      "tensor(21)\n",
      "tensor(20)\n",
      "tensor(19)\n",
      "tensor(18)\n",
      "tensor(17)\n",
      "tensor(16)\n",
      "tensor(15)\n",
      "tensor(14)\n",
      "tensor(13)\n",
      "tensor(12)\n",
      "tensor(11)\n",
      "tensor(10)\n",
      "tensor(9)\n",
      "tensor(8)\n",
      "tensor(7)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "xt = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "\n",
    "for t in torch.arange(T, 0, -1):\n",
    "    print(t)\n",
    "    t = t.to(device)\n",
    "    z = torch.randn(batch_size, 1, 28, 28).to(device) if t > 1 else torch.zeros(batch_size, 1, 28, 28).to(device)\n",
    "    xt_new = 1 / torch.sqrt(alpha[t - 1]) * (xt - (1 - alpha[t - 1])/(torch.sqrt(1 - alpha_bar[t - 1])) * \n",
    "                                                   model(xt, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 28, 28))) + torch.sqrt(beta[t-1]) * z\n",
    "    xt = xt_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76f66843-b77f-4798-a78b-806310d3057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a2b2094a90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xt[0][0].cpu().detach().numpy(), cmap=\"grey\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
