{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4f85a-37b5-472e-8782-a5df13c5d601",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec1af4-1d61-46ef-90b9-b972129d09a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeb867f-c38e-4e5c-ab89-a7e747ead472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d87cd-410b-44ef-ac34-560022867208",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#torch.backends.cudnn.enabled = False\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Downloading MNIST again :) Training (60k) and test(5k) + val(5k) split\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data',\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_dataset = datasets.MNIST('./mnist_data',\n",
    "                               download=True,\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "val_dataset, test_dataset = random_split(test_dataset, [val_size, test_size])\n",
    "\n",
    "# Test set to compare with DDPM paper\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Validation set so we can keep track of approximated FID score while training\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=False, num_workers=num_workers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5630601-e376-4f9d-a13b-cefb9d3dcea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, s=torch.tensor([0.008]), T=torch.tensor([1000])):\n",
    "    return min(torch.cos((t / T + s) / (1 + s) * (torch.pi / 2)).pow(2), 0.999)\n",
    "\n",
    "T = 1000\n",
    "ts = torch.arange(T)\n",
    "alpha_bar = torch.tensor([min(f(t)/f(torch.tensor([0])),0.999) for t in ts]) \n",
    "beta = torch.tensor([1 - alpha_bar[t]/(alpha_bar[t-1]) if t > 0 else torch.tensor([0]) for t in ts])\n",
    "alpha = 1 - beta\n",
    "alpha = alpha.view((1000, 1, 1, 1)).to(device)\n",
    "beta = beta.view((1000, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((1000, 1, 1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0ae1fca-cff3-4b53-86d1-65c59740a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up alpha_bar for training and test so alpha_bar_t = alpha_bar[t]\n",
    "T = 1000\n",
    "beta_start, beta_end = [1e-4, 2e-02]\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1-beta\n",
    "alpha_bar = alpha.clone()\n",
    "for e in range(T-1):\n",
    "    alpha_bar[e+1] *= alpha_bar[e]\n",
    "\n",
    "alpha = alpha.view((1000, 1, 1, 1)).to(device)\n",
    "beta = beta.view((1000, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((1000, 1, 1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fe879-ee13-4434-9a0d-de015ddd4c2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c671dbab-ffe9-4fe5-841a-80042e7593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        channels = [32, 64, 128, 256]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(2, channels[0], kernel_size=3, padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 32, 14, 14)\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=3, padding=1),  # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 64, 7, 7)\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, padding=1),  # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2, padding=1),  # (batchsize, 128, 4, 4)\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=3, padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.tconvs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=0),   # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[2]*2, channels[1], kernel_size=3,\n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[1]*2, channels[0], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels[0]*2,channels[0],kernel_size=3,padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(channels[0],1,kernel_size=1) # (batchsize, 1, 28, 28)\n",
    "            )      \n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_trans = torch.cat((x, t), dim=-3)\n",
    "        signal = x_trans\n",
    "        signals = []\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # print(f\"conv {i}\")\n",
    "            signal = conv(signal)\n",
    "            # print(signal.shape)\n",
    "            if i < len(conv):\n",
    "                signals.append(signal)\n",
    "        \n",
    "        for i, tconv in enumerate(self.tconvs):\n",
    "            # print(f\"tconv {i}\")\n",
    "            # print(f\"signal shape: {signal.shape}\")\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04a5df-da69-407e-9285-90de11992cef",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8403ab0-aea6-492a-98b9-31ab55064c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "epochs = 20\n",
    "model = UNET()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc7e14a-63cd-4432-8f07-43fd00841fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 100), loss: 51272153.933\n",
      "(0, 200), loss: 1195571.882\n",
      "(0, 300), loss: 1105500.100\n",
      "(0, 400), loss: 926615.134\n",
      "(0, 500), loss: 644440.819\n",
      "(0, 600), loss: 483252.698\n",
      "(0, 700), loss: 414561.417\n",
      "(0, 800), loss: 340053.860\n",
      "(0, 900), loss: 352783.727\n",
      "(0, 1000), loss: 327859.833\n",
      "(0, 1100), loss: 318641.735\n",
      "(0, 1200), loss: 309817.303\n",
      "(0, 1300), loss: 306639.262\n",
      "(0, 1400), loss: 295434.576\n",
      "(0, 1500), loss: 295826.158\n",
      "(0, 1600), loss: 295112.673\n",
      "(0, 1700), loss: 283605.434\n",
      "(0, 1800), loss: 493341.323\n",
      "(0, 1900), loss: 286840.616\n",
      "(0, 2000), loss: 320981.884\n",
      "(0, 2100), loss: 696273.059\n",
      "(0, 2200), loss: 403658.335\n",
      "(0, 2300), loss: 1889930.623\n",
      "(0, 2400), loss: 297324.598\n",
      "(0, 2500), loss: 284745.439\n",
      "(0, 2600), loss: 291282.677\n",
      "(0, 2700), loss: 289200.876\n",
      "(0, 2800), loss: 273946.394\n",
      "(0, 2900), loss: 287518.773\n",
      "(0, 3000), loss: 300264.989\n",
      "(0, 3100), loss: 286995.426\n",
      "(0, 3200), loss: 274655.303\n",
      "(0, 3300), loss: 276304.742\n",
      "(0, 3400), loss: 304214.460\n",
      "(0, 3500), loss: 288836.214\n",
      "(0, 3600), loss: 665086.333\n",
      "(0, 3700), loss: 450459.737\n",
      "(1, 100), loss: 1550946.721\n",
      "(1, 200), loss: 381278.130\n",
      "(1, 300), loss: 335342.421\n",
      "(1, 400), loss: 310249.289\n",
      "(1, 500), loss: 302801.436\n",
      "(1, 600), loss: 293372.940\n",
      "(1, 700), loss: 338363.225\n",
      "(1, 800), loss: 407592.533\n",
      "(1, 900), loss: 316941.267\n",
      "(1, 1000), loss: 261225.446\n",
      "(1, 1100), loss: 291647.493\n",
      "(1, 1200), loss: 302497.225\n",
      "(1, 1300), loss: 337077.378\n",
      "(1, 1400), loss: 252507.262\n",
      "(1, 1500), loss: 518264.518\n",
      "(1, 1600), loss: 339686.825\n",
      "(1, 1700), loss: 246507.975\n",
      "(1, 1800), loss: 226450.289\n",
      "(1, 1900), loss: 227502.953\n",
      "(1, 2000), loss: 190122.250\n",
      "(1, 2100), loss: 190673.199\n",
      "(1, 2200), loss: 231810.191\n",
      "(1, 2300), loss: 195747.285\n",
      "(1, 2400), loss: 149227.641\n",
      "(1, 2500), loss: 145559.563\n",
      "(1, 2600), loss: 134579.593\n",
      "(1, 2700), loss: 143082.159\n",
      "(1, 2800), loss: 123636.308\n",
      "(1, 2900), loss: 119761.178\n",
      "(1, 3000), loss: 115174.401\n",
      "(1, 3100), loss: 147182.889\n",
      "(1, 3200), loss: 111734.978\n",
      "(1, 3300), loss: 99506.379\n",
      "(1, 3400), loss: 154884.199\n",
      "(1, 3500), loss: 139281.572\n",
      "(1, 3600), loss: 144408.172\n",
      "(1, 3700), loss: 113687.881\n",
      "(2, 100), loss: 153934.688\n",
      "(2, 200), loss: 116052.534\n",
      "(2, 300), loss: 97693.697\n",
      "(2, 400), loss: 94447.159\n",
      "(2, 500), loss: 85910.605\n",
      "(2, 600), loss: 90753.081\n",
      "(2, 700), loss: 109106.085\n",
      "(2, 800), loss: 83884.064\n",
      "(2, 900), loss: 89613.543\n",
      "(2, 1000), loss: 88328.353\n",
      "(2, 1100), loss: 98733.759\n",
      "(2, 1200), loss: 96363.312\n",
      "(2, 1300), loss: 86885.389\n",
      "(2, 1400), loss: 77688.823\n",
      "(2, 1500), loss: 79459.774\n",
      "(2, 1600), loss: 77607.743\n",
      "(2, 1700), loss: 75293.278\n",
      "(2, 1800), loss: 104396.801\n",
      "(2, 1900), loss: 75391.575\n",
      "(2, 2000), loss: 74844.057\n",
      "(2, 2100), loss: 73454.298\n",
      "(2, 2200), loss: 74529.567\n",
      "(2, 2300), loss: 74608.993\n",
      "(2, 2400), loss: 80693.864\n",
      "(2, 2500), loss: 75225.658\n",
      "(2, 2600), loss: 73782.881\n",
      "(2, 2700), loss: 73579.601\n",
      "(2, 2800), loss: 71751.391\n",
      "(2, 2900), loss: 74486.387\n",
      "(2, 3000), loss: 69181.977\n",
      "(2, 3100), loss: 68069.215\n",
      "(2, 3200), loss: 76121.626\n",
      "(2, 3300), loss: 72055.309\n",
      "(2, 3400), loss: 66665.059\n",
      "(2, 3500), loss: 71381.445\n",
      "(2, 3600), loss: 75769.397\n",
      "(2, 3700), loss: 69080.849\n",
      "(3, 100), loss: 115253.811\n",
      "(3, 200), loss: 63635.682\n",
      "(3, 300), loss: 63371.926\n",
      "(3, 400), loss: 61959.919\n",
      "(3, 500), loss: 74023.734\n",
      "(3, 600), loss: 64644.551\n",
      "(3, 700), loss: 63940.527\n",
      "(3, 800), loss: 63228.573\n",
      "(3, 900), loss: 65272.831\n",
      "(3, 1000), loss: 61046.096\n",
      "(3, 1100), loss: 66154.900\n",
      "(3, 1200), loss: 68343.486\n",
      "(3, 1300), loss: 69838.055\n",
      "(3, 1400), loss: 61822.767\n",
      "(3, 1500), loss: 65119.966\n",
      "(3, 1600), loss: 61317.119\n",
      "(3, 1700), loss: 66561.963\n",
      "(3, 1800), loss: 62567.542\n",
      "(3, 1900), loss: 59245.781\n",
      "(3, 2000), loss: 62960.398\n",
      "(3, 2100), loss: 65017.188\n",
      "(3, 2200), loss: 60310.419\n",
      "(3, 2300), loss: 60239.368\n",
      "(3, 2400), loss: 58858.091\n",
      "(3, 2500), loss: 63699.849\n",
      "(3, 2600), loss: 58107.144\n",
      "(3, 2700), loss: 61350.843\n",
      "(3, 2800), loss: 64688.753\n",
      "(3, 2900), loss: 59149.885\n",
      "(3, 3000), loss: 61585.129\n",
      "(3, 3100), loss: 58367.455\n",
      "(3, 3200), loss: 59509.296\n",
      "(3, 3300), loss: 60224.967\n",
      "(3, 3400), loss: 58484.134\n",
      "(3, 3500), loss: 59713.631\n",
      "(3, 3600), loss: 62485.037\n",
      "(3, 3700), loss: 66674.664\n",
      "(4, 100), loss: 90154.623\n",
      "(4, 200), loss: 52831.700\n",
      "(4, 300), loss: 58363.156\n",
      "(4, 400), loss: 56009.449\n",
      "(4, 500), loss: 58636.117\n",
      "(4, 600), loss: 55253.829\n",
      "(4, 700), loss: 58840.279\n",
      "(4, 800), loss: 57786.250\n",
      "(4, 900), loss: 54600.410\n",
      "(4, 1000), loss: 53966.138\n",
      "(4, 1100), loss: 51984.392\n",
      "(4, 1200), loss: 56135.305\n",
      "(4, 1300), loss: 61824.103\n",
      "(4, 1400), loss: 54888.752\n",
      "(4, 1500), loss: 53979.062\n",
      "(4, 1600), loss: 58893.204\n",
      "(4, 1700), loss: 57445.371\n",
      "(4, 1800), loss: 54397.060\n",
      "(4, 1900), loss: 56728.061\n",
      "(4, 2000), loss: 56075.475\n",
      "(4, 2100), loss: 61076.058\n",
      "(4, 2200), loss: 55909.795\n",
      "(4, 2300), loss: 51870.152\n",
      "(4, 2400), loss: 51399.044\n",
      "(4, 2500), loss: 52854.990\n",
      "(4, 2600), loss: 51986.170\n",
      "(4, 2700), loss: 54751.636\n",
      "(4, 2800), loss: 53839.998\n",
      "(4, 2900), loss: 53500.181\n",
      "(4, 3000), loss: 51830.135\n",
      "(4, 3100), loss: 47821.324\n",
      "(4, 3200), loss: 50729.636\n",
      "(4, 3300), loss: 50999.868\n",
      "(4, 3400), loss: 51363.274\n",
      "(4, 3500), loss: 57135.886\n",
      "(4, 3600), loss: 54166.826\n",
      "(4, 3700), loss: 48814.076\n",
      "(5, 100), loss: 76489.379\n",
      "(5, 200), loss: 54324.055\n",
      "(5, 300), loss: 51097.692\n",
      "(5, 400), loss: 48639.407\n",
      "(5, 500), loss: 52872.509\n",
      "(5, 600), loss: 60073.597\n",
      "(5, 700), loss: 49521.971\n",
      "(5, 800), loss: 49882.558\n",
      "(5, 900), loss: 54309.648\n",
      "(5, 1000), loss: 49300.966\n",
      "(5, 1100), loss: 51252.296\n",
      "(5, 1200), loss: 49440.590\n",
      "(5, 1300), loss: 50721.952\n",
      "(5, 1400), loss: 50221.505\n",
      "(5, 1500), loss: 52314.767\n",
      "(5, 1600), loss: 48203.782\n",
      "(5, 1700), loss: 50572.014\n",
      "(5, 1800), loss: 50521.337\n",
      "(5, 1900), loss: 50545.115\n",
      "(5, 2000), loss: 53155.575\n",
      "(5, 2100), loss: 54164.114\n",
      "(5, 2200), loss: 51305.532\n",
      "(5, 2300), loss: 48905.751\n",
      "(5, 2400), loss: 53075.801\n",
      "(5, 2500), loss: 48020.352\n",
      "(5, 2600), loss: 48102.009\n",
      "(5, 2700), loss: 48419.144\n",
      "(5, 2800), loss: 52576.701\n",
      "(5, 2900), loss: 49900.990\n",
      "(5, 3000), loss: 45330.487\n",
      "(5, 3100), loss: 51149.166\n",
      "(5, 3200), loss: 46532.642\n",
      "(5, 3300), loss: 47502.502\n",
      "(5, 3400), loss: 49927.775\n",
      "(5, 3500), loss: 54717.118\n",
      "(5, 3600), loss: 47347.052\n",
      "(5, 3700), loss: 47520.665\n",
      "(6, 100), loss: 72436.924\n",
      "(6, 200), loss: 48354.350\n",
      "(6, 300), loss: 46294.425\n",
      "(6, 400), loss: 49337.782\n",
      "(6, 500), loss: 50029.021\n",
      "(6, 600), loss: 50944.522\n",
      "(6, 700), loss: 44928.831\n",
      "(6, 800), loss: 46807.015\n",
      "(6, 900), loss: 48501.830\n",
      "(6, 1000), loss: 49041.856\n",
      "(6, 1100), loss: 51558.621\n",
      "(6, 1200), loss: 49080.619\n",
      "(6, 1300), loss: 47722.225\n",
      "(6, 1400), loss: 47620.200\n",
      "(6, 1500), loss: 52825.031\n",
      "(6, 1600), loss: 49150.043\n",
      "(6, 1700), loss: 46101.053\n",
      "(6, 1800), loss: 45093.985\n",
      "(6, 1900), loss: 48649.708\n",
      "(6, 2000), loss: 47380.943\n",
      "(6, 2100), loss: 50527.787\n",
      "(6, 2200), loss: 47898.438\n",
      "(6, 2300), loss: 48001.263\n",
      "(6, 2400), loss: 46419.031\n",
      "(6, 2500), loss: 48679.576\n",
      "(6, 2600), loss: 47023.238\n",
      "(6, 2700), loss: 48183.608\n",
      "(6, 2800), loss: 45941.467\n",
      "(6, 2900), loss: 46126.993\n",
      "(6, 3000), loss: 47396.125\n",
      "(6, 3100), loss: 45304.493\n",
      "(6, 3200), loss: 48410.220\n",
      "(6, 3300), loss: 45618.070\n",
      "(6, 3400), loss: 49277.219\n",
      "(6, 3500), loss: 46701.234\n",
      "(6, 3600), loss: 50406.076\n",
      "(6, 3700), loss: 45763.408\n",
      "(7, 100), loss: 66013.825\n",
      "(7, 200), loss: 48599.110\n",
      "(7, 300), loss: 49928.639\n",
      "(7, 400), loss: 46289.892\n",
      "(7, 500), loss: 45291.368\n",
      "(7, 600), loss: 45435.342\n",
      "(7, 700), loss: 47339.005\n",
      "(7, 800), loss: 47876.564\n",
      "(7, 900), loss: 48129.014\n",
      "(7, 1000), loss: 46124.074\n",
      "(7, 1100), loss: 51844.985\n",
      "(7, 1200), loss: 46975.707\n",
      "(7, 1300), loss: 44708.836\n",
      "(7, 1400), loss: 45165.083\n",
      "(7, 1500), loss: 50541.890\n",
      "(7, 1600), loss: 46307.820\n",
      "(7, 1700), loss: 47142.127\n",
      "(7, 1800), loss: 49100.602\n",
      "(7, 1900), loss: 47259.225\n",
      "(7, 2000), loss: 48398.812\n",
      "(7, 2100), loss: 45022.628\n",
      "(7, 2200), loss: 44892.920\n",
      "(7, 2300), loss: 46604.424\n",
      "(7, 2400), loss: 47360.459\n",
      "(7, 2500), loss: 43079.226\n",
      "(7, 2600), loss: 46032.122\n",
      "(7, 2700), loss: 46015.150\n",
      "(7, 2800), loss: 43903.844\n",
      "(7, 2900), loss: 43849.185\n",
      "(7, 3000), loss: 46035.694\n",
      "(7, 3100), loss: 48970.899\n",
      "(7, 3200), loss: 44038.314\n",
      "(7, 3300), loss: 45385.177\n",
      "(7, 3400), loss: 44347.325\n",
      "(7, 3500), loss: 45453.627\n",
      "(7, 3600), loss: 46260.733\n",
      "(7, 3700), loss: 44637.785\n",
      "(8, 100), loss: 72643.164\n",
      "(8, 200), loss: 48544.179\n",
      "(8, 300), loss: 44981.459\n",
      "(8, 400), loss: 45101.080\n",
      "(8, 500), loss: 45755.428\n",
      "(8, 600), loss: 45607.733\n",
      "(8, 700), loss: 45525.910\n",
      "(8, 800), loss: 45716.068\n",
      "(8, 900), loss: 47399.086\n",
      "(8, 1000), loss: 45324.095\n",
      "(8, 1100), loss: 45515.421\n",
      "(8, 1200), loss: 46650.645\n",
      "(8, 1300), loss: 46674.759\n",
      "(8, 1400), loss: 46063.609\n",
      "(8, 1500), loss: 45003.619\n",
      "(8, 1600), loss: 45509.677\n",
      "(8, 1700), loss: 49150.875\n",
      "(8, 1800), loss: 43914.765\n",
      "(8, 1900), loss: 45213.837\n",
      "(8, 2000), loss: 42947.839\n",
      "(8, 2100), loss: 46226.244\n",
      "(8, 2200), loss: 47011.400\n",
      "(8, 2300), loss: 47780.455\n",
      "(8, 2400), loss: 45152.443\n",
      "(8, 2500), loss: 45203.814\n",
      "(8, 2600), loss: 46504.190\n",
      "(8, 2700), loss: 46316.424\n",
      "(8, 2800), loss: 43537.052\n",
      "(8, 2900), loss: 45791.770\n",
      "(8, 3000), loss: 47877.123\n",
      "(8, 3100), loss: 46787.831\n",
      "(8, 3200), loss: 42790.813\n",
      "(8, 3300), loss: 45340.240\n",
      "(8, 3400), loss: 45850.956\n",
      "(8, 3500), loss: 43824.583\n",
      "(8, 3600), loss: 42801.648\n",
      "(8, 3700), loss: 45457.754\n",
      "(9, 100), loss: 67551.232\n",
      "(9, 200), loss: 48096.003\n",
      "(9, 300), loss: 49857.232\n",
      "(9, 400), loss: 43544.423\n",
      "(9, 500), loss: 45090.769\n",
      "(9, 600), loss: 43327.605\n",
      "(9, 700), loss: 41025.651\n",
      "(9, 800), loss: 43676.946\n",
      "(9, 900), loss: 45449.933\n",
      "(9, 1000), loss: 48082.435\n",
      "(9, 1100), loss: 45894.471\n",
      "(9, 1200), loss: 44378.083\n",
      "(9, 1300), loss: 44443.139\n",
      "(9, 1400), loss: 44933.548\n",
      "(9, 1500), loss: 43523.513\n",
      "(9, 1600), loss: 43761.447\n",
      "(9, 1700), loss: 43009.108\n",
      "(9, 1800), loss: 43555.266\n",
      "(9, 1900), loss: 46258.002\n",
      "(9, 2000), loss: 45231.564\n",
      "(9, 2100), loss: 47183.750\n",
      "(9, 2200), loss: 46303.561\n",
      "(9, 2300), loss: 47192.911\n",
      "(9, 2400), loss: 44012.378\n",
      "(9, 2500), loss: 44991.723\n",
      "(9, 2600), loss: 47188.603\n",
      "(9, 2700), loss: 46662.981\n",
      "(9, 2800), loss: 47226.262\n",
      "(9, 2900), loss: 45360.594\n",
      "(9, 3000), loss: 43006.168\n",
      "(9, 3100), loss: 44764.591\n",
      "(9, 3200), loss: 45246.379\n",
      "(9, 3300), loss: 45454.710\n",
      "(9, 3400), loss: 44619.032\n",
      "(9, 3500), loss: 43253.112\n",
      "(9, 3600), loss: 54473.275\n",
      "(9, 3700), loss: 48085.976\n",
      "(10, 100), loss: 67894.777\n",
      "(10, 200), loss: 45183.683\n",
      "(10, 300), loss: 45149.900\n",
      "(10, 400), loss: 44895.904\n",
      "(10, 500), loss: 45999.314\n",
      "(10, 600), loss: 42124.180\n",
      "(10, 700), loss: 45357.332\n",
      "(10, 800), loss: 44971.455\n",
      "(10, 900), loss: 44547.650\n",
      "(10, 1000), loss: 45493.861\n",
      "(10, 1100), loss: 43889.413\n",
      "(10, 1200), loss: 52035.338\n",
      "(10, 1300), loss: 43938.013\n",
      "(10, 1400), loss: 43369.818\n",
      "(10, 1500), loss: 45859.479\n",
      "(10, 1600), loss: 47955.117\n",
      "(10, 1700), loss: 44224.707\n",
      "(10, 1800), loss: 47240.338\n",
      "(10, 1900), loss: 45000.628\n",
      "(10, 2000), loss: 43043.517\n",
      "(10, 2100), loss: 44011.745\n",
      "(10, 2200), loss: 44724.321\n",
      "(10, 2300), loss: 45224.221\n",
      "(10, 2400), loss: 46178.481\n",
      "(10, 2500), loss: 43764.608\n",
      "(10, 2600), loss: 47425.579\n",
      "(10, 2700), loss: 44770.918\n",
      "(10, 2800), loss: 44032.508\n",
      "(10, 2900), loss: 45821.275\n",
      "(10, 3000), loss: 44830.750\n",
      "(10, 3100), loss: 42081.470\n",
      "(10, 3200), loss: 46095.512\n",
      "(10, 3300), loss: 47237.001\n",
      "(10, 3400), loss: 44031.321\n",
      "(10, 3500), loss: 45497.281\n",
      "(10, 3600), loss: 45737.129\n",
      "(10, 3700), loss: 46174.706\n",
      "(11, 100), loss: 63395.824\n",
      "(11, 200), loss: 45784.388\n",
      "(11, 300), loss: 46355.328\n",
      "(11, 400), loss: 43265.731\n",
      "(11, 500), loss: 43254.558\n",
      "(11, 600), loss: 44477.074\n",
      "(11, 700), loss: 43132.513\n",
      "(11, 800), loss: 44968.764\n",
      "(11, 900), loss: 45037.196\n",
      "(11, 1000), loss: 47019.662\n",
      "(11, 1100), loss: 44643.664\n",
      "(11, 1200), loss: 45840.814\n",
      "(11, 1300), loss: 43260.825\n",
      "(11, 1400), loss: 43498.126\n",
      "(11, 1500), loss: 45697.658\n",
      "(11, 1600), loss: 47086.781\n",
      "(11, 1700), loss: 46190.838\n",
      "(11, 1800), loss: 43505.993\n",
      "(11, 1900), loss: 43721.176\n",
      "(11, 2000), loss: 42974.456\n",
      "(11, 2100), loss: 44911.611\n",
      "(11, 2200), loss: 43280.139\n",
      "(11, 2300), loss: 44798.720\n",
      "(11, 2400), loss: 42200.142\n",
      "(11, 2500), loss: 44334.448\n",
      "(11, 2600), loss: 44559.482\n",
      "(11, 2700), loss: 46470.078\n",
      "(11, 2800), loss: 44484.483\n",
      "(11, 2900), loss: 48295.401\n",
      "(11, 3000), loss: 45578.846\n",
      "(11, 3100), loss: 43456.084\n",
      "(11, 3200), loss: 43817.662\n",
      "(11, 3300), loss: 44650.791\n",
      "(11, 3400), loss: 44712.984\n",
      "(11, 3500), loss: 44744.953\n",
      "(11, 3600), loss: 42728.364\n",
      "(11, 3700), loss: 42304.970\n",
      "(12, 100), loss: 64146.687\n",
      "(12, 200), loss: 43785.623\n",
      "(12, 300), loss: 43477.314\n",
      "(12, 400), loss: 41818.807\n",
      "(12, 500), loss: 45613.976\n",
      "(12, 600), loss: 44545.681\n",
      "(12, 700), loss: 42914.991\n",
      "(12, 800), loss: 44078.042\n",
      "(12, 900), loss: 45834.124\n",
      "(12, 1000), loss: 43189.515\n",
      "(12, 1100), loss: 44261.235\n",
      "(12, 1200), loss: 45074.583\n",
      "(12, 1300), loss: 42420.291\n",
      "(12, 1400), loss: 46607.447\n",
      "(12, 1500), loss: 45001.360\n",
      "(12, 1600), loss: 41732.054\n",
      "(12, 1700), loss: 41343.519\n",
      "(12, 1800), loss: 42823.033\n",
      "(12, 1900), loss: 42710.396\n",
      "(12, 2000), loss: 43224.238\n",
      "(12, 2100), loss: 45666.501\n",
      "(12, 2200), loss: 43703.815\n",
      "(12, 2300), loss: 45068.949\n",
      "(12, 2400), loss: 42391.798\n",
      "(12, 2500), loss: 44184.999\n",
      "(12, 2600), loss: 46349.247\n",
      "(12, 2700), loss: 41960.472\n",
      "(12, 2800), loss: 43850.490\n",
      "(12, 2900), loss: 43610.292\n",
      "(12, 3000), loss: 47041.144\n",
      "(12, 3100), loss: 45216.174\n",
      "(12, 3200), loss: 44277.101\n",
      "(12, 3300), loss: 40606.826\n",
      "(12, 3400), loss: 42501.562\n",
      "(12, 3500), loss: 43908.838\n",
      "(12, 3600), loss: 47728.201\n",
      "(12, 3700), loss: 42800.090\n",
      "(13, 100), loss: 69692.059\n",
      "(13, 200), loss: 42042.414\n",
      "(13, 300), loss: 42525.357\n",
      "(13, 400), loss: 42536.960\n",
      "(13, 500), loss: 43810.528\n",
      "(13, 600), loss: 42540.884\n",
      "(13, 700), loss: 43043.643\n",
      "(13, 800), loss: 43294.515\n",
      "(13, 900), loss: 41973.869\n",
      "(13, 1000), loss: 42307.496\n",
      "(13, 1100), loss: 46005.388\n",
      "(13, 1200), loss: 43516.463\n",
      "(13, 1300), loss: 43354.273\n",
      "(13, 1400), loss: 44975.276\n",
      "(13, 1500), loss: 43796.266\n",
      "(13, 1600), loss: 44593.086\n",
      "(13, 1700), loss: 42859.342\n",
      "(13, 1800), loss: 41907.470\n",
      "(13, 1900), loss: 45574.848\n",
      "(13, 2000), loss: 41574.460\n",
      "(13, 2100), loss: 42655.529\n",
      "(13, 2200), loss: 46897.147\n",
      "(13, 2300), loss: 42896.347\n",
      "(13, 2400), loss: 48828.799\n",
      "(13, 2500), loss: 42605.315\n",
      "(13, 2600), loss: 43204.297\n",
      "(13, 2700), loss: 43590.270\n",
      "(13, 2800), loss: 41197.102\n",
      "(13, 2900), loss: 43305.125\n",
      "(13, 3000), loss: 43484.624\n",
      "(13, 3100), loss: 44068.462\n",
      "(13, 3200), loss: 44822.193\n",
      "(13, 3300), loss: 43018.912\n",
      "(13, 3400), loss: 42936.931\n",
      "(13, 3500), loss: 42693.284\n",
      "(13, 3600), loss: 43765.333\n",
      "(13, 3700), loss: 44748.610\n",
      "(14, 100), loss: 66400.106\n",
      "(14, 200), loss: 43798.648\n",
      "(14, 300), loss: 42499.640\n",
      "(14, 400), loss: 42383.899\n",
      "(14, 500), loss: 43579.655\n",
      "(14, 600), loss: 42260.558\n",
      "(14, 700), loss: 45057.866\n",
      "(14, 800), loss: 43257.749\n",
      "(14, 900), loss: 43373.238\n",
      "(14, 1000), loss: 44071.435\n",
      "(14, 1100), loss: 44625.461\n",
      "(14, 1200), loss: 43386.858\n",
      "(14, 1300), loss: 42481.796\n",
      "(14, 1400), loss: 41773.949\n",
      "(14, 1500), loss: 40700.447\n",
      "(14, 1600), loss: 41644.282\n",
      "(14, 1700), loss: 43603.003\n",
      "(14, 1800), loss: 45010.723\n",
      "(14, 1900), loss: 42864.625\n",
      "(14, 2000), loss: 42568.212\n",
      "(14, 2100), loss: 42238.125\n",
      "(14, 2200), loss: 43665.709\n",
      "(14, 2300), loss: 43436.053\n",
      "(14, 2400), loss: 43721.773\n",
      "(14, 2500), loss: 43796.278\n",
      "(14, 2600), loss: 43149.256\n",
      "(14, 2700), loss: 45601.591\n",
      "(14, 2800), loss: 41731.508\n",
      "(14, 2900), loss: 43193.285\n",
      "(14, 3000), loss: 43049.899\n",
      "(14, 3100), loss: 43632.862\n",
      "(14, 3200), loss: 42723.799\n",
      "(14, 3300), loss: 44598.003\n",
      "(14, 3400), loss: 42101.202\n",
      "(14, 3500), loss: 45472.426\n",
      "(14, 3600), loss: 41661.712\n",
      "(14, 3700), loss: 42835.777\n",
      "(15, 100), loss: 64751.837\n",
      "(15, 200), loss: 45797.767\n",
      "(15, 300), loss: 43461.387\n",
      "(15, 400), loss: 43787.737\n",
      "(15, 500), loss: 45435.500\n",
      "(15, 600), loss: 45286.102\n",
      "(15, 700), loss: 45703.834\n",
      "(15, 800), loss: 42808.113\n",
      "(15, 900), loss: 42391.713\n",
      "(15, 1000), loss: 43525.411\n",
      "(15, 1100), loss: 41509.422\n",
      "(15, 1200), loss: 43738.858\n",
      "(15, 1300), loss: 42337.441\n",
      "(15, 1400), loss: 42720.402\n",
      "(15, 1500), loss: 42803.670\n",
      "(15, 1600), loss: 44001.144\n",
      "(15, 1700), loss: 43317.917\n",
      "(15, 1800), loss: 42649.231\n",
      "(15, 1900), loss: 44936.965\n",
      "(15, 2000), loss: 43745.667\n",
      "(15, 2100), loss: 42709.426\n",
      "(15, 2200), loss: 43873.188\n",
      "(15, 2300), loss: 43979.600\n",
      "(15, 2400), loss: 42052.878\n",
      "(15, 2500), loss: 46095.921\n",
      "(15, 2600), loss: 44404.353\n",
      "(15, 2700), loss: 41774.701\n",
      "(15, 2800), loss: 42783.640\n",
      "(15, 2900), loss: 40422.943\n",
      "(15, 3000), loss: 43762.010\n",
      "(15, 3100), loss: 43007.412\n",
      "(15, 3200), loss: 42706.892\n",
      "(15, 3300), loss: 42031.839\n",
      "(15, 3400), loss: 42916.662\n",
      "(15, 3500), loss: 44237.688\n",
      "(15, 3600), loss: 42294.425\n",
      "(15, 3700), loss: 39936.674\n",
      "(16, 100), loss: 63060.777\n",
      "(16, 200), loss: 43657.651\n",
      "(16, 300), loss: 42415.368\n",
      "(16, 400), loss: 42557.063\n",
      "(16, 500), loss: 42162.907\n",
      "(16, 600), loss: 41809.295\n",
      "(16, 700), loss: 43283.243\n",
      "(16, 800), loss: 42465.762\n",
      "(16, 900), loss: 41582.491\n",
      "(16, 1000), loss: 45175.748\n",
      "(16, 1100), loss: 46517.736\n",
      "(16, 1200), loss: 42357.986\n",
      "(16, 1300), loss: 42984.883\n",
      "(16, 1400), loss: 42734.048\n",
      "(16, 1500), loss: 43464.434\n",
      "(16, 1600), loss: 43120.359\n",
      "(16, 1700), loss: 42588.066\n",
      "(16, 1800), loss: 43530.805\n",
      "(16, 1900), loss: 43069.715\n",
      "(16, 2000), loss: 40569.782\n",
      "(16, 2100), loss: 43469.630\n",
      "(16, 2200), loss: 44713.207\n",
      "(16, 2300), loss: 41992.307\n",
      "(16, 2400), loss: 44826.904\n",
      "(16, 2500), loss: 41945.329\n",
      "(16, 2600), loss: 41814.145\n",
      "(16, 2700), loss: 45900.033\n",
      "(16, 2800), loss: 42920.875\n",
      "(16, 2900), loss: 40748.747\n",
      "(16, 3000), loss: 42287.675\n",
      "(16, 3100), loss: 42514.995\n",
      "(16, 3200), loss: 44593.061\n",
      "(16, 3300), loss: 41906.930\n",
      "(16, 3400), loss: 42710.840\n",
      "(16, 3500), loss: 43076.912\n",
      "(16, 3600), loss: 43220.060\n",
      "(16, 3700), loss: 46059.672\n",
      "(17, 100), loss: 62859.860\n",
      "(17, 200), loss: 42562.299\n",
      "(17, 300), loss: 42487.825\n",
      "(17, 400), loss: 42480.470\n",
      "(17, 500), loss: 44789.243\n",
      "(17, 600), loss: 41725.334\n",
      "(17, 700), loss: 43571.381\n",
      "(17, 800), loss: 43012.013\n",
      "(17, 900), loss: 40169.476\n",
      "(17, 1000), loss: 42236.356\n",
      "(17, 1100), loss: 42767.210\n",
      "(17, 1200), loss: 44732.863\n",
      "(17, 1300), loss: 42780.896\n",
      "(17, 1400), loss: 40329.280\n",
      "(17, 1500), loss: 42741.118\n",
      "(17, 1600), loss: 43581.190\n",
      "(17, 1700), loss: 42193.887\n",
      "(17, 1800), loss: 45235.020\n",
      "(17, 1900), loss: 43899.715\n",
      "(17, 2000), loss: 42451.191\n",
      "(17, 2100), loss: 42125.892\n",
      "(17, 2200), loss: 40851.396\n",
      "(17, 2300), loss: 43329.311\n",
      "(17, 2400), loss: 43370.732\n",
      "(17, 2500), loss: 43743.827\n",
      "(17, 2600), loss: 40495.474\n",
      "(17, 2700), loss: 41399.912\n",
      "(17, 2800), loss: 44006.460\n",
      "(17, 2900), loss: 41081.760\n",
      "(17, 3000), loss: 41445.307\n",
      "(17, 3100), loss: 42544.940\n",
      "(17, 3200), loss: 42836.592\n",
      "(17, 3300), loss: 40586.131\n",
      "(17, 3400), loss: 42606.816\n",
      "(17, 3500), loss: 42458.727\n",
      "(17, 3600), loss: 44147.081\n",
      "(17, 3700), loss: 42331.682\n",
      "(18, 100), loss: 59669.379\n",
      "(18, 200), loss: 40832.402\n",
      "(18, 300), loss: 42869.532\n",
      "(18, 400), loss: 41449.060\n",
      "(18, 500), loss: 42381.608\n",
      "(18, 600), loss: 42831.593\n",
      "(18, 700), loss: 44260.185\n",
      "(18, 800), loss: 41830.531\n",
      "(18, 900), loss: 43310.366\n",
      "(18, 1000), loss: 43208.707\n",
      "(18, 1100), loss: 44639.524\n",
      "(18, 1200), loss: 41867.346\n",
      "(18, 1300), loss: 41829.060\n",
      "(18, 1400), loss: 42968.958\n",
      "(18, 1500), loss: 44000.593\n",
      "(18, 1600), loss: 42178.346\n",
      "(18, 1700), loss: 42192.932\n",
      "(18, 1800), loss: 40215.563\n",
      "(18, 1900), loss: 42083.688\n",
      "(18, 2000), loss: 41368.262\n",
      "(18, 2100), loss: 46163.586\n",
      "(18, 2200), loss: 41582.878\n",
      "(18, 2300), loss: 40763.384\n",
      "(18, 2400), loss: 42776.381\n",
      "(18, 2500), loss: 41809.981\n",
      "(18, 2600), loss: 40886.171\n",
      "(18, 2700), loss: 43000.866\n",
      "(18, 2800), loss: 43205.284\n",
      "(18, 2900), loss: 38542.576\n",
      "(18, 3000), loss: 42368.927\n",
      "(18, 3100), loss: 41380.379\n",
      "(18, 3200), loss: 43753.168\n",
      "(18, 3300), loss: 42416.954\n",
      "(18, 3400), loss: 40972.020\n",
      "(18, 3500), loss: 41007.992\n",
      "(18, 3600), loss: 42498.903\n",
      "(18, 3700), loss: 45556.400\n",
      "(19, 100), loss: 63190.137\n",
      "(19, 200), loss: 43709.652\n",
      "(19, 300), loss: 40801.769\n",
      "(19, 400), loss: 42167.396\n",
      "(19, 500), loss: 41805.305\n",
      "(19, 600), loss: 42177.561\n",
      "(19, 700), loss: 41427.877\n",
      "(19, 800), loss: 42067.592\n",
      "(19, 900), loss: 43516.247\n",
      "(19, 1000), loss: 45388.343\n",
      "(19, 1100), loss: 41820.848\n",
      "(19, 1200), loss: 42413.316\n",
      "(19, 1300), loss: 42450.346\n",
      "(19, 1400), loss: 41812.376\n",
      "(19, 1500), loss: 42501.681\n",
      "(19, 1600), loss: 44145.422\n",
      "(19, 1700), loss: 43054.498\n",
      "(19, 1800), loss: 43454.842\n",
      "(19, 1900), loss: 40792.444\n",
      "(19, 2000), loss: 41514.446\n",
      "(19, 2100), loss: 40824.008\n",
      "(19, 2200), loss: 43539.096\n",
      "(19, 2300), loss: 39027.237\n",
      "(19, 2400), loss: 40567.006\n",
      "(19, 2500), loss: 42597.941\n",
      "(19, 2600), loss: 42249.482\n",
      "(19, 2700), loss: 42916.842\n",
      "(19, 2800), loss: 43681.979\n",
      "(19, 2900), loss: 41494.973\n",
      "(19, 3000), loss: 46591.612\n",
      "(19, 3100), loss: 42558.911\n",
      "(19, 3200), loss: 43190.605\n",
      "(19, 3300), loss: 43813.177\n",
      "(19, 3400), loss: 40096.144\n",
      "(19, 3500), loss: 41207.112\n",
      "(19, 3600), loss: 41021.705\n",
      "(19, 3700), loss: 42073.226\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for e, data in enumerate(train_loader):\n",
    "        x0, _ = data\n",
    "        x0 = x0.to(device)\n",
    "        t = torch.randint(1, T+1, (batch_size,)).to(device)\n",
    "        eps = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        # print(eps.shape)\n",
    "        # print(x0.shape)\n",
    "        loss = criterion(eps, model(torch.sqrt(alpha_bar[t-1]) * x0 + \n",
    "                                    torch.sqrt(1 - alpha_bar[t-1]) * eps, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 28, 28)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if e % 100 == 99:\n",
    "            print(f'{epoch, e+1}, loss: {running_loss:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    if epoch % 5 == 4:\n",
    "        torch.save(model.state_dict(), f\"DDPM_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a74a6-6786-43c8-9b7b-569eb01df2f2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cd8cdb-77e0-4881-ace7-79d6da4848ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (tconvs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53f69f28-7031-48bc-96d4-85b61ba8d524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bdb0269950>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "xt = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "\n",
    "for t in torch.arange(T, 0, -1):\n",
    "    #print(t)\n",
    "    t = t.to(device)\n",
    "    z = torch.randn(batch_size, 1, 28, 28).to(device) if t > 1 else torch.zeros(batch_size, 1, 28, 28).to(device)\n",
    "    xt_new = 1 / torch.sqrt(alpha[t - 1]) * (xt - (1 - alpha[t - 1])/(torch.sqrt(1 - alpha_bar[t - 1])) * \n",
    "                                                   model(xt, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 28, 28))) + torch.sqrt(beta[t-1]) * z\n",
    "    xt = xt_new\n",
    "    #if t == 1:\n",
    "        #print((xt - (1 - alpha[t - 1])/(torch.sqrt(1 - alpha_bar[t - 1]))))\n",
    "plt.imshow(xt[0][0].cpu().detach().numpy(), cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfbadb66-3f6a-4dd8-b8db-4c0d1662a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.]]], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10)\n",
    "alpha_bar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f66843-b77f-4798-a78b-806310d3057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b4c76d89d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xt[0][0].cpu().detach().numpy(), cmap=\"grey\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
