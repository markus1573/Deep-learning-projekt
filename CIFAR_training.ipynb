{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4f85a-37b5-472e-8782-a5df13c5d601",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec1af4-1d61-46ef-90b9-b972129d09a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeb867f-c38e-4e5c-ab89-a7e747ead472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d87cd-410b-44ef-ac34-560022867208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#torch.backends.cudnn.enabled = False\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "pin_memory = False if device == torch.device('cpu') else True\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## Potential changes - Markus\n",
    "\n",
    "# Normalize input images to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Downloading MNIST again :) Training (60k) and test(5k) + val(5k) split\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./CIFAR_data',\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            drop_last=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10('./CIFAR_data',\n",
    "                               download=True,\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "val_dataset, test_dataset = random_split(test_dataset, [val_size, test_size])\n",
    "\n",
    "# Test set to compare with DDPM paper\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "\n",
    "# Validation set so we can keep track of approximated FID score while training\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ae1fca-cff3-4b53-86d1-65c59740a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sets up alpha_bar for training and test so alpha_bar_t = alpha_bar[t]\n",
    "# T = 1000\n",
    "# beta_start, beta_end = [1e-4, 2e-02]\n",
    "# beta = torch.linspace(beta_start, beta_end, T)\n",
    "# alpha = 1-beta\n",
    "# alpha_bar = alpha.clone()\n",
    "# for e in range(T-1):\n",
    "#     alpha_bar[e+1] *= alpha_bar[e]\n",
    "\n",
    "# alpha = alpha.view((T, 1, 1, 1)).to(device)\n",
    "# beta = beta.view((T, 1, 1, 1)).to(device)\n",
    "# alpha_bar = alpha_bar.view((T, 1, 1, 1)).to(device)\n",
    "\n",
    "\n",
    "### Potential changes - Markus\n",
    "T = 1000\n",
    "beta_start, beta_end = 1e-4, 2e-2\n",
    "beta = torch.linspace(beta_start, beta_end, T)  # Linear noise schedule\n",
    "alpha = 1.0 - beta\n",
    "alpha_bar = torch.cumprod(alpha, dim=0)  # Cumulative product for alpha_bar\n",
    "\n",
    "# Reshape for broadcasting (if required for your model)\n",
    "alpha = alpha.view((T, 1, 1, 1)).to(device)\n",
    "beta = beta.view((T, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((T, 1, 1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fe879-ee13-4434-9a0d-de015ddd4c2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671dbab-ffe9-4fe5-841a-80042e7593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        channels = [32, 64, 128, 256]\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(4, channels[0], kernel_size=3, padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 32, 14, 14)\n",
    "                nn.Conv2d(channels[0], channels[1], kernel_size=3, padding=1),  # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 64, 7, 7)\n",
    "                nn.Conv2d(channels[1], channels[2], kernel_size=3, padding=1),  # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2, padding=1),  # (batchsize, 128, 4, 4)\n",
    "                nn.Conv2d(channels[2], channels[3], kernel_size=3, padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.tconvs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[3], channels[2], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=0),   # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[2]*2, channels[1], kernel_size=3,\n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(channels[1]*2, channels[0], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(channels[0]*2,channels[0],kernel_size=3,padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(channels[0],3,kernel_size=1) # (batchsize, 1, 28, 28)\n",
    "            )      \n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_trans = torch.cat((x, t), dim=-3)\n",
    "        signal = x_trans\n",
    "        signals = []\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # print(f\"conv {i}\")\n",
    "            signal = conv(signal)\n",
    "            # print(signal.shape)\n",
    "            if i < len(self.convs)-1:\n",
    "                signals.append(signal)\n",
    "                \n",
    "        for i, tconv in enumerate(self.tconvs):\n",
    "            # print(f\"tconv {i}\")\n",
    "            # print(f\"signal shape: {signal.shape}\")\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04a5df-da69-407e-9285-90de11992cef",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8403ab0-aea6-492a-98b9-31ab55064c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "epochs = 200\n",
    "model = UNET()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc7e14a-63cd-4432-8f07-43fd00841fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 9 but got size 32 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(t\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(batch_size, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(xt\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(eps, model(xt, t\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)))\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 68\u001b[0m, in \u001b[0;36mUNET.forward\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     66\u001b[0m         signal \u001b[38;5;241m=\u001b[39m tconv(signal)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m         signal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((signal, signals[\u001b[38;5;241m-\u001b[39mi]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     69\u001b[0m         signal \u001b[38;5;241m=\u001b[39m tconv(signal)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signal\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 9 but got size 32 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for e, data in enumerate(train_loader):\n",
    "        x0, _ = data\n",
    "        x0 = x0.to(device)\n",
    "        t = torch.randint(1, T+1, (batch_size,)).to(device)\n",
    "        eps = torch.randn(batch_size, 1, 32, 32).to(device)\n",
    "        # print(eps.shape)\n",
    "        \n",
    "        xt = torch.sqrt(alpha_bar[t-1]) * x0 + torch.sqrt(1 - alpha_bar[t-1]) * eps\n",
    "        #print(x0.shape)\n",
    "        print(t.shape)\n",
    "        print(t.view(batch_size, 1, 1, 1).expand(batch_size, 3, 32, 32).shape)\n",
    "        print(xt.shape)\n",
    "        loss = criterion(eps, model(xt, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 32, 32)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if e % 100 == 99:\n",
    "            print(f'{epoch, e+1}, Average_loss: {running_loss/100:.3f}')\n",
    "            running_loss = 0.0\n",
    "    if epoch % 10 == 9:\n",
    "        torch.save(model.state_dict(), f\"DDPM_CIFAR_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a74a6-6786-43c8-9b7b-569eb01df2f2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f69f28-7031-48bc-96d4-85b61ba8d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000)\n",
      "tensor(999)\n",
      "tensor(998)\n",
      "tensor(997)\n",
      "tensor(996)\n",
      "tensor(995)\n",
      "tensor(994)\n",
      "tensor(993)\n",
      "tensor(992)\n",
      "tensor(991)\n",
      "tensor(990)\n",
      "tensor(989)\n",
      "tensor(988)\n",
      "tensor(987)\n",
      "tensor(986)\n",
      "tensor(985)\n",
      "tensor(984)\n",
      "tensor(983)\n",
      "tensor(982)\n",
      "tensor(981)\n",
      "tensor(980)\n",
      "tensor(979)\n",
      "tensor(978)\n",
      "tensor(977)\n",
      "tensor(976)\n",
      "tensor(975)\n",
      "tensor(974)\n",
      "tensor(973)\n",
      "tensor(972)\n",
      "tensor(971)\n",
      "tensor(970)\n",
      "tensor(969)\n",
      "tensor(968)\n",
      "tensor(967)\n",
      "tensor(966)\n",
      "tensor(965)\n",
      "tensor(964)\n",
      "tensor(963)\n",
      "tensor(962)\n",
      "tensor(961)\n",
      "tensor(960)\n",
      "tensor(959)\n",
      "tensor(958)\n",
      "tensor(957)\n",
      "tensor(956)\n",
      "tensor(955)\n",
      "tensor(954)\n",
      "tensor(953)\n",
      "tensor(952)\n",
      "tensor(951)\n",
      "tensor(950)\n",
      "tensor(949)\n",
      "tensor(948)\n",
      "tensor(947)\n",
      "tensor(946)\n",
      "tensor(945)\n",
      "tensor(944)\n",
      "tensor(943)\n",
      "tensor(942)\n",
      "tensor(941)\n",
      "tensor(940)\n",
      "tensor(939)\n",
      "tensor(938)\n",
      "tensor(937)\n",
      "tensor(936)\n",
      "tensor(935)\n",
      "tensor(934)\n",
      "tensor(933)\n",
      "tensor(932)\n",
      "tensor(931)\n",
      "tensor(930)\n",
      "tensor(929)\n",
      "tensor(928)\n",
      "tensor(927)\n",
      "tensor(926)\n",
      "tensor(925)\n",
      "tensor(924)\n",
      "tensor(923)\n",
      "tensor(922)\n",
      "tensor(921)\n",
      "tensor(920)\n",
      "tensor(919)\n",
      "tensor(918)\n",
      "tensor(917)\n",
      "tensor(916)\n",
      "tensor(915)\n",
      "tensor(914)\n",
      "tensor(913)\n",
      "tensor(912)\n",
      "tensor(911)\n",
      "tensor(910)\n",
      "tensor(909)\n",
      "tensor(908)\n",
      "tensor(907)\n",
      "tensor(906)\n",
      "tensor(905)\n",
      "tensor(904)\n",
      "tensor(903)\n",
      "tensor(902)\n",
      "tensor(901)\n",
      "tensor(900)\n",
      "tensor(899)\n",
      "tensor(898)\n",
      "tensor(897)\n",
      "tensor(896)\n",
      "tensor(895)\n",
      "tensor(894)\n",
      "tensor(893)\n",
      "tensor(892)\n",
      "tensor(891)\n",
      "tensor(890)\n",
      "tensor(889)\n",
      "tensor(888)\n",
      "tensor(887)\n",
      "tensor(886)\n",
      "tensor(885)\n",
      "tensor(884)\n",
      "tensor(883)\n",
      "tensor(882)\n",
      "tensor(881)\n",
      "tensor(880)\n",
      "tensor(879)\n",
      "tensor(878)\n",
      "tensor(877)\n",
      "tensor(876)\n",
      "tensor(875)\n",
      "tensor(874)\n",
      "tensor(873)\n",
      "tensor(872)\n",
      "tensor(871)\n",
      "tensor(870)\n",
      "tensor(869)\n",
      "tensor(868)\n",
      "tensor(867)\n",
      "tensor(866)\n",
      "tensor(865)\n",
      "tensor(864)\n",
      "tensor(863)\n",
      "tensor(862)\n",
      "tensor(861)\n",
      "tensor(860)\n",
      "tensor(859)\n",
      "tensor(858)\n",
      "tensor(857)\n",
      "tensor(856)\n",
      "tensor(855)\n",
      "tensor(854)\n",
      "tensor(853)\n",
      "tensor(852)\n",
      "tensor(851)\n",
      "tensor(850)\n",
      "tensor(849)\n",
      "tensor(848)\n",
      "tensor(847)\n",
      "tensor(846)\n",
      "tensor(845)\n",
      "tensor(844)\n",
      "tensor(843)\n",
      "tensor(842)\n",
      "tensor(841)\n",
      "tensor(840)\n",
      "tensor(839)\n",
      "tensor(838)\n",
      "tensor(837)\n",
      "tensor(836)\n",
      "tensor(835)\n",
      "tensor(834)\n",
      "tensor(833)\n",
      "tensor(832)\n",
      "tensor(831)\n",
      "tensor(830)\n",
      "tensor(829)\n",
      "tensor(828)\n",
      "tensor(827)\n",
      "tensor(826)\n",
      "tensor(825)\n",
      "tensor(824)\n",
      "tensor(823)\n",
      "tensor(822)\n",
      "tensor(821)\n",
      "tensor(820)\n",
      "tensor(819)\n",
      "tensor(818)\n",
      "tensor(817)\n",
      "tensor(816)\n",
      "tensor(815)\n",
      "tensor(814)\n",
      "tensor(813)\n",
      "tensor(812)\n",
      "tensor(811)\n",
      "tensor(810)\n",
      "tensor(809)\n",
      "tensor(808)\n",
      "tensor(807)\n",
      "tensor(806)\n",
      "tensor(805)\n",
      "tensor(804)\n",
      "tensor(803)\n",
      "tensor(802)\n",
      "tensor(801)\n",
      "tensor(800)\n",
      "tensor(799)\n",
      "tensor(798)\n",
      "tensor(797)\n",
      "tensor(796)\n",
      "tensor(795)\n",
      "tensor(794)\n",
      "tensor(793)\n",
      "tensor(792)\n",
      "tensor(791)\n",
      "tensor(790)\n",
      "tensor(789)\n",
      "tensor(788)\n",
      "tensor(787)\n",
      "tensor(786)\n",
      "tensor(785)\n",
      "tensor(784)\n",
      "tensor(783)\n",
      "tensor(782)\n",
      "tensor(781)\n",
      "tensor(780)\n",
      "tensor(779)\n",
      "tensor(778)\n",
      "tensor(777)\n",
      "tensor(776)\n",
      "tensor(775)\n",
      "tensor(774)\n",
      "tensor(773)\n",
      "tensor(772)\n",
      "tensor(771)\n",
      "tensor(770)\n",
      "tensor(769)\n",
      "tensor(768)\n",
      "tensor(767)\n",
      "tensor(766)\n",
      "tensor(765)\n",
      "tensor(764)\n",
      "tensor(763)\n",
      "tensor(762)\n",
      "tensor(761)\n",
      "tensor(760)\n",
      "tensor(759)\n",
      "tensor(758)\n",
      "tensor(757)\n",
      "tensor(756)\n",
      "tensor(755)\n",
      "tensor(754)\n",
      "tensor(753)\n",
      "tensor(752)\n",
      "tensor(751)\n",
      "tensor(750)\n",
      "tensor(749)\n",
      "tensor(748)\n",
      "tensor(747)\n",
      "tensor(746)\n",
      "tensor(745)\n",
      "tensor(744)\n",
      "tensor(743)\n",
      "tensor(742)\n",
      "tensor(741)\n",
      "tensor(740)\n",
      "tensor(739)\n",
      "tensor(738)\n",
      "tensor(737)\n",
      "tensor(736)\n",
      "tensor(735)\n",
      "tensor(734)\n",
      "tensor(733)\n",
      "tensor(732)\n",
      "tensor(731)\n",
      "tensor(730)\n",
      "tensor(729)\n",
      "tensor(728)\n",
      "tensor(727)\n",
      "tensor(726)\n",
      "tensor(725)\n",
      "tensor(724)\n",
      "tensor(723)\n",
      "tensor(722)\n",
      "tensor(721)\n",
      "tensor(720)\n",
      "tensor(719)\n",
      "tensor(718)\n",
      "tensor(717)\n",
      "tensor(716)\n",
      "tensor(715)\n",
      "tensor(714)\n",
      "tensor(713)\n",
      "tensor(712)\n",
      "tensor(711)\n",
      "tensor(710)\n",
      "tensor(709)\n",
      "tensor(708)\n",
      "tensor(707)\n",
      "tensor(706)\n",
      "tensor(705)\n",
      "tensor(704)\n",
      "tensor(703)\n",
      "tensor(702)\n",
      "tensor(701)\n",
      "tensor(700)\n",
      "tensor(699)\n",
      "tensor(698)\n",
      "tensor(697)\n",
      "tensor(696)\n",
      "tensor(695)\n",
      "tensor(694)\n",
      "tensor(693)\n",
      "tensor(692)\n",
      "tensor(691)\n",
      "tensor(690)\n",
      "tensor(689)\n",
      "tensor(688)\n",
      "tensor(687)\n",
      "tensor(686)\n",
      "tensor(685)\n",
      "tensor(684)\n",
      "tensor(683)\n",
      "tensor(682)\n",
      "tensor(681)\n",
      "tensor(680)\n",
      "tensor(679)\n",
      "tensor(678)\n",
      "tensor(677)\n",
      "tensor(676)\n",
      "tensor(675)\n",
      "tensor(674)\n",
      "tensor(673)\n",
      "tensor(672)\n",
      "tensor(671)\n",
      "tensor(670)\n",
      "tensor(669)\n",
      "tensor(668)\n",
      "tensor(667)\n",
      "tensor(666)\n",
      "tensor(665)\n",
      "tensor(664)\n",
      "tensor(663)\n",
      "tensor(662)\n",
      "tensor(661)\n",
      "tensor(660)\n",
      "tensor(659)\n",
      "tensor(658)\n",
      "tensor(657)\n",
      "tensor(656)\n",
      "tensor(655)\n",
      "tensor(654)\n",
      "tensor(653)\n",
      "tensor(652)\n",
      "tensor(651)\n",
      "tensor(650)\n",
      "tensor(649)\n",
      "tensor(648)\n",
      "tensor(647)\n",
      "tensor(646)\n",
      "tensor(645)\n",
      "tensor(644)\n",
      "tensor(643)\n",
      "tensor(642)\n",
      "tensor(641)\n",
      "tensor(640)\n",
      "tensor(639)\n",
      "tensor(638)\n",
      "tensor(637)\n",
      "tensor(636)\n",
      "tensor(635)\n",
      "tensor(634)\n",
      "tensor(633)\n",
      "tensor(632)\n",
      "tensor(631)\n",
      "tensor(630)\n",
      "tensor(629)\n",
      "tensor(628)\n",
      "tensor(627)\n",
      "tensor(626)\n",
      "tensor(625)\n",
      "tensor(624)\n",
      "tensor(623)\n",
      "tensor(622)\n",
      "tensor(621)\n",
      "tensor(620)\n",
      "tensor(619)\n",
      "tensor(618)\n",
      "tensor(617)\n",
      "tensor(616)\n",
      "tensor(615)\n",
      "tensor(614)\n",
      "tensor(613)\n",
      "tensor(612)\n",
      "tensor(611)\n",
      "tensor(610)\n",
      "tensor(609)\n",
      "tensor(608)\n",
      "tensor(607)\n",
      "tensor(606)\n",
      "tensor(605)\n",
      "tensor(604)\n",
      "tensor(603)\n",
      "tensor(602)\n",
      "tensor(601)\n",
      "tensor(600)\n",
      "tensor(599)\n",
      "tensor(598)\n",
      "tensor(597)\n",
      "tensor(596)\n",
      "tensor(595)\n",
      "tensor(594)\n",
      "tensor(593)\n",
      "tensor(592)\n",
      "tensor(591)\n",
      "tensor(590)\n",
      "tensor(589)\n",
      "tensor(588)\n",
      "tensor(587)\n",
      "tensor(586)\n",
      "tensor(585)\n",
      "tensor(584)\n",
      "tensor(583)\n",
      "tensor(582)\n",
      "tensor(581)\n",
      "tensor(580)\n",
      "tensor(579)\n",
      "tensor(578)\n",
      "tensor(577)\n",
      "tensor(576)\n",
      "tensor(575)\n",
      "tensor(574)\n",
      "tensor(573)\n",
      "tensor(572)\n",
      "tensor(571)\n",
      "tensor(570)\n",
      "tensor(569)\n",
      "tensor(568)\n",
      "tensor(567)\n",
      "tensor(566)\n",
      "tensor(565)\n",
      "tensor(564)\n",
      "tensor(563)\n",
      "tensor(562)\n",
      "tensor(561)\n",
      "tensor(560)\n",
      "tensor(559)\n",
      "tensor(558)\n",
      "tensor(557)\n",
      "tensor(556)\n",
      "tensor(555)\n",
      "tensor(554)\n",
      "tensor(553)\n",
      "tensor(552)\n",
      "tensor(551)\n",
      "tensor(550)\n",
      "tensor(549)\n",
      "tensor(548)\n",
      "tensor(547)\n",
      "tensor(546)\n",
      "tensor(545)\n",
      "tensor(544)\n",
      "tensor(543)\n",
      "tensor(542)\n",
      "tensor(541)\n",
      "tensor(540)\n",
      "tensor(539)\n",
      "tensor(538)\n",
      "tensor(537)\n",
      "tensor(536)\n",
      "tensor(535)\n",
      "tensor(534)\n",
      "tensor(533)\n",
      "tensor(532)\n",
      "tensor(531)\n",
      "tensor(530)\n",
      "tensor(529)\n",
      "tensor(528)\n",
      "tensor(527)\n",
      "tensor(526)\n",
      "tensor(525)\n",
      "tensor(524)\n",
      "tensor(523)\n",
      "tensor(522)\n",
      "tensor(521)\n",
      "tensor(520)\n",
      "tensor(519)\n",
      "tensor(518)\n",
      "tensor(517)\n",
      "tensor(516)\n",
      "tensor(515)\n",
      "tensor(514)\n",
      "tensor(513)\n",
      "tensor(512)\n",
      "tensor(511)\n",
      "tensor(510)\n",
      "tensor(509)\n",
      "tensor(508)\n",
      "tensor(507)\n",
      "tensor(506)\n",
      "tensor(505)\n",
      "tensor(504)\n",
      "tensor(503)\n",
      "tensor(502)\n",
      "tensor(501)\n",
      "tensor(500)\n",
      "tensor(499)\n",
      "tensor(498)\n",
      "tensor(497)\n",
      "tensor(496)\n",
      "tensor(495)\n",
      "tensor(494)\n",
      "tensor(493)\n",
      "tensor(492)\n",
      "tensor(491)\n",
      "tensor(490)\n",
      "tensor(489)\n",
      "tensor(488)\n",
      "tensor(487)\n",
      "tensor(486)\n",
      "tensor(485)\n",
      "tensor(484)\n",
      "tensor(483)\n",
      "tensor(482)\n",
      "tensor(481)\n",
      "tensor(480)\n",
      "tensor(479)\n",
      "tensor(478)\n",
      "tensor(477)\n",
      "tensor(476)\n",
      "tensor(475)\n",
      "tensor(474)\n",
      "tensor(473)\n",
      "tensor(472)\n",
      "tensor(471)\n",
      "tensor(470)\n",
      "tensor(469)\n",
      "tensor(468)\n",
      "tensor(467)\n",
      "tensor(466)\n",
      "tensor(465)\n",
      "tensor(464)\n",
      "tensor(463)\n",
      "tensor(462)\n",
      "tensor(461)\n",
      "tensor(460)\n",
      "tensor(459)\n",
      "tensor(458)\n",
      "tensor(457)\n",
      "tensor(456)\n",
      "tensor(455)\n",
      "tensor(454)\n",
      "tensor(453)\n",
      "tensor(452)\n",
      "tensor(451)\n",
      "tensor(450)\n",
      "tensor(449)\n",
      "tensor(448)\n",
      "tensor(447)\n",
      "tensor(446)\n",
      "tensor(445)\n",
      "tensor(444)\n",
      "tensor(443)\n",
      "tensor(442)\n",
      "tensor(441)\n",
      "tensor(440)\n",
      "tensor(439)\n",
      "tensor(438)\n",
      "tensor(437)\n",
      "tensor(436)\n",
      "tensor(435)\n",
      "tensor(434)\n",
      "tensor(433)\n",
      "tensor(432)\n",
      "tensor(431)\n",
      "tensor(430)\n",
      "tensor(429)\n",
      "tensor(428)\n",
      "tensor(427)\n",
      "tensor(426)\n",
      "tensor(425)\n",
      "tensor(424)\n",
      "tensor(423)\n",
      "tensor(422)\n",
      "tensor(421)\n",
      "tensor(420)\n",
      "tensor(419)\n",
      "tensor(418)\n",
      "tensor(417)\n",
      "tensor(416)\n",
      "tensor(415)\n",
      "tensor(414)\n",
      "tensor(413)\n",
      "tensor(412)\n",
      "tensor(411)\n",
      "tensor(410)\n",
      "tensor(409)\n",
      "tensor(408)\n",
      "tensor(407)\n",
      "tensor(406)\n",
      "tensor(405)\n",
      "tensor(404)\n",
      "tensor(403)\n",
      "tensor(402)\n",
      "tensor(401)\n",
      "tensor(400)\n",
      "tensor(399)\n",
      "tensor(398)\n",
      "tensor(397)\n",
      "tensor(396)\n",
      "tensor(395)\n",
      "tensor(394)\n",
      "tensor(393)\n",
      "tensor(392)\n",
      "tensor(391)\n",
      "tensor(390)\n",
      "tensor(389)\n",
      "tensor(388)\n",
      "tensor(387)\n",
      "tensor(386)\n",
      "tensor(385)\n",
      "tensor(384)\n",
      "tensor(383)\n",
      "tensor(382)\n",
      "tensor(381)\n",
      "tensor(380)\n",
      "tensor(379)\n",
      "tensor(378)\n",
      "tensor(377)\n",
      "tensor(376)\n",
      "tensor(375)\n",
      "tensor(374)\n",
      "tensor(373)\n",
      "tensor(372)\n",
      "tensor(371)\n",
      "tensor(370)\n",
      "tensor(369)\n",
      "tensor(368)\n",
      "tensor(367)\n",
      "tensor(366)\n",
      "tensor(365)\n",
      "tensor(364)\n",
      "tensor(363)\n",
      "tensor(362)\n",
      "tensor(361)\n",
      "tensor(360)\n",
      "tensor(359)\n",
      "tensor(358)\n",
      "tensor(357)\n",
      "tensor(356)\n",
      "tensor(355)\n",
      "tensor(354)\n",
      "tensor(353)\n",
      "tensor(352)\n",
      "tensor(351)\n",
      "tensor(350)\n",
      "tensor(349)\n",
      "tensor(348)\n",
      "tensor(347)\n",
      "tensor(346)\n",
      "tensor(345)\n",
      "tensor(344)\n",
      "tensor(343)\n",
      "tensor(342)\n",
      "tensor(341)\n",
      "tensor(340)\n",
      "tensor(339)\n",
      "tensor(338)\n",
      "tensor(337)\n",
      "tensor(336)\n",
      "tensor(335)\n",
      "tensor(334)\n",
      "tensor(333)\n",
      "tensor(332)\n",
      "tensor(331)\n",
      "tensor(330)\n",
      "tensor(329)\n",
      "tensor(328)\n",
      "tensor(327)\n",
      "tensor(326)\n",
      "tensor(325)\n",
      "tensor(324)\n",
      "tensor(323)\n",
      "tensor(322)\n",
      "tensor(321)\n",
      "tensor(320)\n",
      "tensor(319)\n",
      "tensor(318)\n",
      "tensor(317)\n",
      "tensor(316)\n",
      "tensor(315)\n",
      "tensor(314)\n",
      "tensor(313)\n",
      "tensor(312)\n",
      "tensor(311)\n",
      "tensor(310)\n",
      "tensor(309)\n",
      "tensor(308)\n",
      "tensor(307)\n",
      "tensor(306)\n",
      "tensor(305)\n",
      "tensor(304)\n",
      "tensor(303)\n",
      "tensor(302)\n",
      "tensor(301)\n",
      "tensor(300)\n",
      "tensor(299)\n",
      "tensor(298)\n",
      "tensor(297)\n",
      "tensor(296)\n",
      "tensor(295)\n",
      "tensor(294)\n",
      "tensor(293)\n",
      "tensor(292)\n",
      "tensor(291)\n",
      "tensor(290)\n",
      "tensor(289)\n",
      "tensor(288)\n",
      "tensor(287)\n",
      "tensor(286)\n",
      "tensor(285)\n",
      "tensor(284)\n",
      "tensor(283)\n",
      "tensor(282)\n",
      "tensor(281)\n",
      "tensor(280)\n",
      "tensor(279)\n",
      "tensor(278)\n",
      "tensor(277)\n",
      "tensor(276)\n",
      "tensor(275)\n",
      "tensor(274)\n",
      "tensor(273)\n",
      "tensor(272)\n",
      "tensor(271)\n",
      "tensor(270)\n",
      "tensor(269)\n",
      "tensor(268)\n",
      "tensor(267)\n",
      "tensor(266)\n",
      "tensor(265)\n",
      "tensor(264)\n",
      "tensor(263)\n",
      "tensor(262)\n",
      "tensor(261)\n",
      "tensor(260)\n",
      "tensor(259)\n",
      "tensor(258)\n",
      "tensor(257)\n",
      "tensor(256)\n",
      "tensor(255)\n",
      "tensor(254)\n",
      "tensor(253)\n",
      "tensor(252)\n",
      "tensor(251)\n",
      "tensor(250)\n",
      "tensor(249)\n",
      "tensor(248)\n",
      "tensor(247)\n",
      "tensor(246)\n",
      "tensor(245)\n",
      "tensor(244)\n",
      "tensor(243)\n",
      "tensor(242)\n",
      "tensor(241)\n",
      "tensor(240)\n",
      "tensor(239)\n",
      "tensor(238)\n",
      "tensor(237)\n",
      "tensor(236)\n",
      "tensor(235)\n",
      "tensor(234)\n",
      "tensor(233)\n",
      "tensor(232)\n",
      "tensor(231)\n",
      "tensor(230)\n",
      "tensor(229)\n",
      "tensor(228)\n",
      "tensor(227)\n",
      "tensor(226)\n",
      "tensor(225)\n",
      "tensor(224)\n",
      "tensor(223)\n",
      "tensor(222)\n",
      "tensor(221)\n",
      "tensor(220)\n",
      "tensor(219)\n",
      "tensor(218)\n",
      "tensor(217)\n",
      "tensor(216)\n",
      "tensor(215)\n",
      "tensor(214)\n",
      "tensor(213)\n",
      "tensor(212)\n",
      "tensor(211)\n",
      "tensor(210)\n",
      "tensor(209)\n",
      "tensor(208)\n",
      "tensor(207)\n",
      "tensor(206)\n",
      "tensor(205)\n",
      "tensor(204)\n",
      "tensor(203)\n",
      "tensor(202)\n",
      "tensor(201)\n",
      "tensor(200)\n",
      "tensor(199)\n",
      "tensor(198)\n",
      "tensor(197)\n",
      "tensor(196)\n",
      "tensor(195)\n",
      "tensor(194)\n",
      "tensor(193)\n",
      "tensor(192)\n",
      "tensor(191)\n",
      "tensor(190)\n",
      "tensor(189)\n",
      "tensor(188)\n",
      "tensor(187)\n",
      "tensor(186)\n",
      "tensor(185)\n",
      "tensor(184)\n",
      "tensor(183)\n",
      "tensor(182)\n",
      "tensor(181)\n",
      "tensor(180)\n",
      "tensor(179)\n",
      "tensor(178)\n",
      "tensor(177)\n",
      "tensor(176)\n",
      "tensor(175)\n",
      "tensor(174)\n",
      "tensor(173)\n",
      "tensor(172)\n",
      "tensor(171)\n",
      "tensor(170)\n",
      "tensor(169)\n",
      "tensor(168)\n",
      "tensor(167)\n",
      "tensor(166)\n",
      "tensor(165)\n",
      "tensor(164)\n",
      "tensor(163)\n",
      "tensor(162)\n",
      "tensor(161)\n",
      "tensor(160)\n",
      "tensor(159)\n",
      "tensor(158)\n",
      "tensor(157)\n",
      "tensor(156)\n",
      "tensor(155)\n",
      "tensor(154)\n",
      "tensor(153)\n",
      "tensor(152)\n",
      "tensor(151)\n",
      "tensor(150)\n",
      "tensor(149)\n",
      "tensor(148)\n",
      "tensor(147)\n",
      "tensor(146)\n",
      "tensor(145)\n",
      "tensor(144)\n",
      "tensor(143)\n",
      "tensor(142)\n",
      "tensor(141)\n",
      "tensor(140)\n",
      "tensor(139)\n",
      "tensor(138)\n",
      "tensor(137)\n",
      "tensor(136)\n",
      "tensor(135)\n",
      "tensor(134)\n",
      "tensor(133)\n",
      "tensor(132)\n",
      "tensor(131)\n",
      "tensor(130)\n",
      "tensor(129)\n",
      "tensor(128)\n",
      "tensor(127)\n",
      "tensor(126)\n",
      "tensor(125)\n",
      "tensor(124)\n",
      "tensor(123)\n",
      "tensor(122)\n",
      "tensor(121)\n",
      "tensor(120)\n",
      "tensor(119)\n",
      "tensor(118)\n",
      "tensor(117)\n",
      "tensor(116)\n",
      "tensor(115)\n",
      "tensor(114)\n",
      "tensor(113)\n",
      "tensor(112)\n",
      "tensor(111)\n",
      "tensor(110)\n",
      "tensor(109)\n",
      "tensor(108)\n",
      "tensor(107)\n",
      "tensor(106)\n",
      "tensor(105)\n",
      "tensor(104)\n",
      "tensor(103)\n",
      "tensor(102)\n",
      "tensor(101)\n",
      "tensor(100)\n",
      "tensor(99)\n",
      "tensor(98)\n",
      "tensor(97)\n",
      "tensor(96)\n",
      "tensor(95)\n",
      "tensor(94)\n",
      "tensor(93)\n",
      "tensor(92)\n",
      "tensor(91)\n",
      "tensor(90)\n",
      "tensor(89)\n",
      "tensor(88)\n",
      "tensor(87)\n",
      "tensor(86)\n",
      "tensor(85)\n",
      "tensor(84)\n",
      "tensor(83)\n",
      "tensor(82)\n",
      "tensor(81)\n",
      "tensor(80)\n",
      "tensor(79)\n",
      "tensor(78)\n",
      "tensor(77)\n",
      "tensor(76)\n",
      "tensor(75)\n",
      "tensor(74)\n",
      "tensor(73)\n",
      "tensor(72)\n",
      "tensor(71)\n",
      "tensor(70)\n",
      "tensor(69)\n",
      "tensor(68)\n",
      "tensor(67)\n",
      "tensor(66)\n",
      "tensor(65)\n",
      "tensor(64)\n",
      "tensor(63)\n",
      "tensor(62)\n",
      "tensor(61)\n",
      "tensor(60)\n",
      "tensor(59)\n",
      "tensor(58)\n",
      "tensor(57)\n",
      "tensor(56)\n",
      "tensor(55)\n",
      "tensor(54)\n",
      "tensor(53)\n",
      "tensor(52)\n",
      "tensor(51)\n",
      "tensor(50)\n",
      "tensor(49)\n",
      "tensor(48)\n",
      "tensor(47)\n",
      "tensor(46)\n",
      "tensor(45)\n",
      "tensor(44)\n",
      "tensor(43)\n",
      "tensor(42)\n",
      "tensor(41)\n",
      "tensor(40)\n",
      "tensor(39)\n",
      "tensor(38)\n",
      "tensor(37)\n",
      "tensor(36)\n",
      "tensor(35)\n",
      "tensor(34)\n",
      "tensor(33)\n",
      "tensor(32)\n",
      "tensor(31)\n",
      "tensor(30)\n",
      "tensor(29)\n",
      "tensor(28)\n",
      "tensor(27)\n",
      "tensor(26)\n",
      "tensor(25)\n",
      "tensor(24)\n",
      "tensor(23)\n",
      "tensor(22)\n",
      "tensor(21)\n",
      "tensor(20)\n",
      "tensor(19)\n",
      "tensor(18)\n",
      "tensor(17)\n",
      "tensor(16)\n",
      "tensor(15)\n",
      "tensor(14)\n",
      "tensor(13)\n",
      "tensor(12)\n",
      "tensor(11)\n",
      "tensor(10)\n",
      "tensor(9)\n",
      "tensor(8)\n",
      "tensor(7)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    batch_size = 1\n",
    "    xt = torch.randn(batch_size, 1, 32, 32).to(device)\n",
    "\n",
    "    for t in torch.arange(T, 0, -1):\n",
    "        print(t)\n",
    "        t = t.to(device)\n",
    "        z = torch.randn(batch_size, 1, 32, 32).to(device) if t > 1 else torch.zeros(batch_size, 1, 32, 32).to(device)\n",
    "        xt_new = 1 / torch.sqrt(alpha[t - 1]) * (xt - (1 - alpha[t - 1])/(torch.sqrt(1 - alpha_bar[t - 1])) * \n",
    "                                                    model(xt, t.view(batch_size, 1, 1, 1).expand(batch_size, 1, 32, 32))) + torch.sqrt(beta[t-1]) * z\n",
    "        xt = xt_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76f66843-b77f-4798-a78b-806310d3057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef6e4a0710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xt[0][0].cpu().detach().numpy(), cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6bf278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
