{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4f85a-37b5-472e-8782-a5df13c5d601",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec1af4-1d61-46ef-90b9-b972129d09a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeb867f-c38e-4e5c-ab89-a7e747ead472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d87cd-410b-44ef-ac34-560022867208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#torch.backends.cudnn.enabled = False\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "pin_memory = False if device == torch.device('cpu') else True\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "# Normalize input images to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "reverse_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: (x + 1) / 2)  # Reverse the normalization to get values in [0, 1]\n",
    "])\n",
    "\n",
    "# Downloading MNIST again :) Training (60k) and test(5k) + val(5k) split\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./CIFAR_data',\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            drop_last=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10('./CIFAR_data',\n",
    "                               download=True,\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "val_dataset, test_dataset = random_split(test_dataset, [val_size, test_size])\n",
    "\n",
    "# Test set to compare with DDPM paper\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "\n",
    "# Validation set so we can keep track of approximated FID score while training\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0ae1fca-cff3-4b53-86d1-65c59740a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cosine noise schedule\n",
    "def f(t, s=torch.tensor([0.008]), T=torch.tensor([1000])):\n",
    "    return min(torch.cos((t / T + s) / (1 + s) * (torch.pi / 2)).pow(2), 0.999)\n",
    "\n",
    "T = 1000\n",
    "ts = torch.arange(T)\n",
    "alpha_bar = torch.tensor([min(f(t)/f(torch.tensor([0])),0.999) for t in ts]) \n",
    "beta = torch.tensor([1 - alpha_bar[t]/(alpha_bar[t-1]) if t > 0 else torch.tensor([0]) for t in ts])\n",
    "alpha = 1 - beta\n",
    "alpha = alpha.view((1000, 1, 1, 1)).to(device)\n",
    "beta = beta.view((1000, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((1000, 1, 1, 1)).to(device)\n",
    "\n",
    "\n",
    "# # Linear noise schedule\n",
    "# T = 1000\n",
    "# beta_start, beta_end = 1e-4, 2e-2\n",
    "# beta = torch.linspace(beta_start, beta_end, T)  # Linear noise schedule\n",
    "# alpha = 1.0 - beta\n",
    "# alpha_bar = torch.cumprod(alpha, dim=0)  # Cumulative product for alpha_bar\n",
    "\n",
    "# # Reshape for broadcasting (if required for your model)\n",
    "# alpha = alpha.view((T, 1, 1, 1)).to(device)\n",
    "# beta = beta.view((T, 1, 1, 1)).to(device)\n",
    "# alpha_bar = alpha_bar.view((T, 1, 1, 1)).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fe879-ee13-4434-9a0d-de015ddd4c2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4681b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -torch.arange(half_dim, dtype=torch.float32) * math.log(10000) / half_dim\n",
    "        ).to(t.device)\n",
    "        angles = t[:, None] * freqs[None, :]\n",
    "        return torch.cat([angles.sin(), angles.cos()], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8eb1e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(LinearTimeEmbedding, self).__init__()\n",
    "        self.projection = nn.Linear(1, embedding_dim)  # Project the scalar to the embedding dimension\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.projection(t.unsqueeze(-1))  # Add an extra dimension for the projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c671dbab-ffe9-4fe5-841a-80042e7593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        self.channels = [3,32, 64, 128, 256]\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(3, self.channels[1], kernel_size=3, padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 32, 14, 14)\n",
    "                nn.Conv2d(self.channels[1], self.channels[2], kernel_size=3, padding=1),  # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 64, 7, 7)\n",
    "                nn.Conv2d(self.channels[2], self.channels[3], kernel_size=3, padding=1),  # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 128, 4, 4)\n",
    "                nn.Conv2d(self.channels[3], self.channels[4], kernel_size=3, padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.tconvs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[4], self.channels[3], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 128, 7, 7)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[3]*2, self.channels[2], kernel_size=3,\n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 64, 14, 14)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[2]*2, self.channels[1], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.channels[1]*2, self.channels[1], kernel_size=3, padding=1),  # (batchsize, 32, 28, 28)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(self.channels[1], 3, kernel_size=1)  # (batchsize, 1, 28, 28)\n",
    "            )      \n",
    "        ])\n",
    "        \n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        signal = x\n",
    "        signals = []\n",
    "\n",
    "        # Pass through the encoding layers\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            lin_time = nn.Linear(128, self.channels[i],device=device) # 128 is the size of the time embedding.\n",
    "            t_emb_processed = lin_time(t_emb).view(-1, self.channels[i], 1, 1)\n",
    "            signal= t_emb_processed+signal\n",
    "            signal = conv(signal)\n",
    "            if i < len(self.convs)-1:\n",
    "                signals.append(signal)\n",
    "\n",
    "        for i, tconv in enumerate(self.tconvs):\n",
    "            lin_time = nn.Linear(128, self.channels[-i-1],device=device)\n",
    "            t_emb_processed = lin_time(t_emb).view(-1, self.channels[-i-1], 1, 1)\n",
    "            signal= signal+t_emb_processed\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "\n",
    "        return signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04a5df-da69-407e-9285-90de11992cef",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8403ab0-aea6-492a-98b9-31ab55064c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "epochs = 200\n",
    "model = UNET()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "running_loss = 0\n",
    "\n",
    "# Initialize the linear time embedding layer\n",
    "time_embedding_dim = 128  # You can set this to any suitable size\n",
    "time_embedding_layer = SinusoidalEmbedding(time_embedding_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7e14a-63cd-4432-8f07-43fd00841fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for e, data in enumerate(train_loader):\n",
    "        x0, _ = data\n",
    "        x0 = x0.to(device)\n",
    "        t = torch.randint(1, T+1, (batch_size,), device=device)\n",
    "        t_emb = time_embedding_layer(t)  # Shape: [batch_size, embedding_dim]\n",
    "        eps = torch.randn_like(x0).to(device)\n",
    "        x_t = torch.sqrt(alpha_bar[t-1]) * x0 + torch.sqrt(1 - alpha_bar[t-1]) * eps\n",
    "        predicted_eps = model(x_t, t_emb)  # Pass the precomputed embedding to the model\n",
    "        loss = criterion(predicted_eps, eps)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if e % 100 == 99:\n",
    "            print(f\"Epoch {epoch}, Batch {e+1}, Average Loss: {running_loss / 100:.4f}\")\n",
    "            running_loss = 0.0  \n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        torch.save(model.state_dict(), f\"DDPM_CIFAR_{epoch+1}.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a74a6-6786-43c8-9b7b-569eb01df2f2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f69f28-7031-48bc-96d4-85b61ba8d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = None\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(load_model, map_location=device))\n",
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    batch_size = 1\n",
    "    xt = torch.randn(batch_size, 3, 32, 32).to(device)\n",
    "\n",
    "    for t in torch.arange(T, 0, -1):\n",
    "        t = t.reshape(1)\n",
    "        t = t.to(device)\n",
    "        t_emb = time_embedding_layer(t.float())\n",
    "        z = torch.randn(batch_size, 3, 32, 32).to(device) if t > 1 else torch.zeros(batch_size, 3, 32, 32).to(device)\n",
    "        \n",
    "        xt_new = 1 / torch.sqrt(alpha[t - 1]) * (xt - (1 - alpha[t - 1])/(torch.sqrt(1 - alpha_bar[t - 1])) * \n",
    "                                                    model(xt, t_emb)) + torch.sqrt(beta[t-1]) * z\n",
    "        xt = xt_new\n",
    "\n",
    "image = torch.permute(xt,(2,3,1,0))\n",
    "image = image.reshape(32,32,3)\n",
    "print(image.max())\n",
    "print(image.min())\n",
    "#weird clipping\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7612842",
   "metadata": {},
   "source": [
    "# Overfit one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ac8f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "\n",
    "model = UNET().to(device)\n",
    "# Initialize the linear time embedding layer\n",
    "time_embedding_dim = 128  # You can set this to any suitable size\n",
    "time_embedding_layer = SinusoidalEmbedding(time_embedding_dim).to(device)\n",
    "\n",
    "# Get a single image from the batch\n",
    "single_batch, _ = next(iter(train_loader))\n",
    "single_batch = single_batch[0].unsqueeze(0).to(device)\n",
    "single_batchs = single_batch.repeat(batch_size, 1, 1, 1)\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "plot_every = 400\n",
    "\n",
    "# Training loop to overfit one batch\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    t = torch.randint(0, T, (batch_size,), device=device)\n",
    "    t_emb = time_embedding_layer(t)  # Shape: [batch_size, embedding_dim]\n",
    "    eps = torch.randn_like(single_batchs).to(device)\n",
    "    x_t = torch.sqrt(alpha_bar[t]) * single_batchs + torch.sqrt(1 - alpha_bar[t]) * eps\n",
    "    predicted_eps = model(x_t, t_emb)  # Pass the precomputed embedding to the model\n",
    "    loss = criterion(predicted_eps, eps)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # if epoch % plot_every == 0:\n",
    "    #     with torch.inference_mode():\n",
    "    #         model.eval()\n",
    "    #         t = torch.randint(0, T, (1,), device=device)\n",
    "    #         t_emb = time_embedding_layer(t)\n",
    "    #         eps = torch.randn_like(single_batch).to(device)\n",
    "    #         x_t = torch.sqrt(alpha_bar[t]) * single_batch + torch.sqrt(1 - alpha_bar[t]) * eps\n",
    "    #         predicted_eps = model(x_t, t_emb)\n",
    "    #         reconstructed = x_t - predicted_eps\n",
    "    #         fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
    "    #         axs[0].imshow(predicted_eps[0][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    #         axs[0].set_title(\"Predicted Noise\")\n",
    "    #         axs[1].imshow(eps[0][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    #         axs[1].set_title(\"True Noise\")\n",
    "    #         axs[2].imshow(np.abs(predicted_eps[0][0].cpu().detach().numpy()-eps[0][0].cpu().detach().numpy()), cmap=\"gray\")\n",
    "    #         axs[2].set_title(\"Difference in noise\")\n",
    "    #         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a72823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a random noise tensor\n",
    "xt = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "# Perform the reverse diffusion process\n",
    "with torch.no_grad():\n",
    "    for t in torch.arange(T-1, -1, -1):\n",
    "        t = t.reshape(1).to(device)\n",
    "        t_emb = time_embedding_layer(t.float())\n",
    "        z = torch.randn(1, 3, 32, 32).to(device) if t > 1 else torch.zeros(1, 3, 32, 32).to(device)\n",
    "        \n",
    "        xt_new = 1 / torch.sqrt(alpha[t]) * (xt - (1 - alpha[t]) / torch.sqrt(1 - alpha_bar[t]) * model(xt, t_emb)) + torch.sqrt(beta[t]) * z\n",
    "        xt = xt_new\n",
    "\n",
    "# Plot the generated image\n",
    "fig,axs = plt.subplots(1, 2, tight_layout=True)\n",
    "axs[0].imshow(reverse_transform(xt[0].cpu().detach()))\n",
    "axs[0].set_title(\"Generated Image\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[1].imshow(reverse_transform(single_batch[0].cpu().detach()))\n",
    "axs[1].set_title(\"Original Image\")\n",
    "axs[1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb7c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
