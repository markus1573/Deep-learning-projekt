{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def4f85a-37b5-472e-8782-a5df13c5d601",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec1af4-1d61-46ef-90b9-b972129d09a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eeb867f-c38e-4e5c-ab89-a7e747ead472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch.autograd import Variable\n",
    "from IPython.display import clear_output\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d87cd-410b-44ef-ac34-560022867208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "#torch.backends.cudnn.enabled = False\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "pin_memory = False if device == torch.device('cpu') else True\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "\n",
    "# Normalize input images to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "reverse_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: (x + 1) / 2),  # Reverse the normalization to get values in [0, 1]\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1)),\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))\n",
    "])\n",
    "\n",
    "\n",
    "# Downloading MNIST again :) Training (60k) and test(5k) + val(5k) split\n",
    "train_loader = torch.utils.data.DataLoader(datasets.CIFAR10('./CIFAR_data',\n",
    "                                            download=True,\n",
    "                                            train=True,\n",
    "                                            transform=transform),\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory,\n",
    "                                            drop_last=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10('./CIFAR_data',\n",
    "                               download=True,\n",
    "                               train=False,\n",
    "                               transform=transform)\n",
    "\n",
    "val_dataset, test_dataset = random_split(test_dataset, [val_size, test_size])\n",
    "\n",
    "# Test set to compare with DDPM paper\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "\n",
    "# Validation set so we can keep track of approximated FID score while training\n",
    "validation_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=num_workers,\n",
    "                                            pin_memory=pin_memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ae1fca-cff3-4b53-86d1-65c59740a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE SCHEDULE\n",
    "def f(t, s=torch.tensor([0.008]), T=torch.tensor([1000])):\n",
    "    return (torch.cos((t / T + s) / (1 + s) * (torch.pi / 2)).pow(2)).clamp(max=0.99999)\n",
    "\n",
    "T = 1000\n",
    "ts = torch.arange(T)\n",
    "alpha_bar = torch.tensor([(f(t)/f(torch.tensor([0]))).clamp(max=0.99999) for t in ts]) \n",
    "beta = torch.tensor([1 - alpha_bar[t]/(alpha_bar[t-1]) if t > 0 else torch.tensor([0]) for t in ts])\n",
    "alpha = 1 - beta\n",
    "alpha = alpha.view((T, 1, 1, 1)).to(device)\n",
    "beta = beta.view((T, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((T, 1, 1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up alpha_bar for training and test so alpha_bar_t = alpha_bar[t]\n",
    "# LINEAR SCHEDULE\n",
    "\"\"\"T = 1000\n",
    "beta_start, beta_end = [1e-4, 2e-02]\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1-beta\n",
    "alpha_bar = alpha.clone()\n",
    "for e in range(T-1):\n",
    "    alpha_bar[e+1] *= alpha_bar[e]\n",
    "\n",
    "alpha = alpha.view((1000, 1, 1, 1)).to(device)\n",
    "beta = beta.view((1000, 1, 1, 1)).to(device)\n",
    "alpha_bar = alpha_bar.view((1000, 1, 1, 1)).to(device)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fe879-ee13-4434-9a0d-de015ddd4c2f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4681b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -torch.arange(half_dim, dtype=torch.float32) * math.log(10000) / half_dim\n",
    "        ).to(t.device)\n",
    "        angles = t[:, None] * freqs[None, :]\n",
    "        return torch.cat([angles.sin(), angles.cos()], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb1e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(LinearTimeEmbedding, self).__init__()\n",
    "        self.projection = nn.Linear(1, embedding_dim)  # Project the scalar to the embedding dimension\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.projection(t.unsqueeze(-1))  # Add an extra dimension for the projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c671dbab-ffe9-4fe5-841a-80042e7593b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "        self.channels = [3,32, 64, 128, 256, 512]\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.channels[0], self.channels[1], kernel_size=3, padding=1),  # (batchsize, 32, 32, 32)\n",
    "                nn.GroupNorm(4, self.channels[1]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 32, 16, 16)\n",
    "                nn.Conv2d(self.channels[1], self.channels[2], kernel_size=3, padding=1),  # (batchsize, 64, 16, 16)\n",
    "                nn.GroupNorm(4, self.channels[2]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 64, 7, 7)\n",
    "                nn.Conv2d(self.channels[2], self.channels[3], kernel_size=3, padding=1),  # (batchsize, 128, 8, 8)\n",
    "                nn.GroupNorm(8, self.channels[3]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 128, 4, 4)\n",
    "                nn.Conv2d(self.channels[3], self.channels[4], kernel_size=3, padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.GroupNorm(8, self.channels[4]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(0.2)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.MaxPool2d(2),  # (batchsize, 256, 2, 2)\n",
    "                nn.Conv2d(self.channels[4], self.channels[5], kernel_size=3, padding=1),  # (batchsize, 512, 2, 2)\n",
    "                nn.GroupNorm(8, self.channels[5]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(0.2)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.tconvs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[5], self.channels[4], kernel_size=3,\n",
    "                                      stride=2, padding=1, output_padding=1),  # (batchsize, 256, 4, 4)\n",
    "                nn.GroupNorm(8, self.channels[4]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(0.2)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[4]*2, self.channels[3], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 128, 8, 8)\n",
    "                nn.GroupNorm(8, self.channels[3]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(0.2)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[3]*2, self.channels[2], kernel_size=3,\n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 64, 16, 16)\n",
    "                nn.GroupNorm(8, self.channels[2]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.channels[2]*2, self.channels[1], kernel_size=3, \n",
    "                                   stride=2, padding=1, output_padding=1),   # (batchsize, 32, 32, 32)\n",
    "                nn.GroupNorm(4, self.channels[1]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1)\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(self.channels[1]*2, self.channels[1], kernel_size=3, padding=1),  # (batchsize, 32, 32, 32)\n",
    "                nn.GroupNorm(4, self.channels[1]),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout2d(0.1),\n",
    "                nn.Conv2d(self.channels[1], self.channels[0], kernel_size=1)  # (batchsize, 3, 32, 32)\n",
    "            )      \n",
    "        ])\n",
    "        \n",
    "        self.time_layers = nn.ModuleList([\n",
    "                nn.Linear(128, self.channels[i]) for i in range(len(self.channels))\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        signal = x\n",
    "        signals = []\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            # print(f\"signal shape: {signal.shape}\")\n",
    "            t_emb_processed = self.time_layers[i](t_emb).view(-1, self.channels[i], 1, 1)\n",
    "            signal= t_emb_processed+signal\n",
    "            signal = conv(signal)\n",
    "            if i < len(self.convs)-1:\n",
    "                signals.append(signal)\n",
    "        \n",
    "        for i, tconv in enumerate(self.tconvs):\n",
    "            # print(f\"signal shape: {signal.shape}\")\n",
    "            # print(f\"signals[-{i}] shape: {signals[-i].shape}\")\n",
    "            # print()\n",
    "            t_emb_processed = self.time_layers[-(i + 1)](t_emb).view(-1, self.channels[-(i + 1)], 1, 1)\n",
    "            signal= signal+t_emb_processed\n",
    "            if i == 0:\n",
    "                signal = tconv(signal)\n",
    "            else:\n",
    "                signal = torch.cat((signal, signals[-i]), dim=-3)\n",
    "                signal = tconv(signal)\n",
    "\n",
    "        return signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04a5df-da69-407e-9285-90de11992cef",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8403ab0-aea6-492a-98b9-31ab55064c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "epochs = 200\n",
    "model = UNET()\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "running_loss = 0\n",
    "\n",
    "# Initialize the linear time embedding layer\n",
    "time_embedding_dim = 128  # You can set this to any suitable size\n",
    "time_embedding_layer = SinusoidalEmbedding(time_embedding_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7e14a-63cd-4432-8f07-43fd00841fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n",
      "tensor(1.) tensor(-1.)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(x0\u001b[38;5;241m.\u001b[39mmax(),x0\u001b[38;5;241m.\u001b[39mmin())\n\u001b[0;32m     20\u001b[0m x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(alpha_bar[t]) \u001b[38;5;241m*\u001b[39m x0 \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_bar[t]) \u001b[38;5;241m*\u001b[39m eps\n\u001b[1;32m---> 21\u001b[0m predicted_eps \u001b[38;5;241m=\u001b[39m model(x_t, t_emb)  \u001b[38;5;66;03m# Pass the precomputed embedding to the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predicted_eps, eps)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 108\u001b[0m, in \u001b[0;36mUNET.forward\u001b[1;34m(self, x, t_emb)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m         signal \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((signal, signals[\u001b[38;5;241m-\u001b[39mi]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m         signal \u001b[38;5;241m=\u001b[39m tconv(signal)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signal\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\shan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load_model = None\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(load_model, map_location=device))\n",
    "\n",
    "losses = []\n",
    "batchlosses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for e, data in enumerate(train_loader):\n",
    "        x0, _ = data\n",
    "        x0 = x0.to(device)\n",
    "        t = torch.randint(0, T, (batch_size,), device=device)\n",
    "        t_norm = t.float() / T\n",
    "        t_emb = time_embedding_layer(t_norm)  # Shape: [batch_size, embedding_dim]\n",
    "        eps = torch.randn_like(x0).to(device)\n",
    "        eps = 2*(eps-eps.min())/(eps.max()-eps.min())-1\n",
    "        x_t = torch.sqrt(alpha_bar[t]) * x0 + torch.sqrt(1 - alpha_bar[t]) * eps\n",
    "        predicted_eps = model(x_t, t_emb)  # Pass the precomputed embedding to the model\n",
    "        loss = criterion(predicted_eps, eps)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "        # if e % 100 == 99:\n",
    "        #     print(f\"Epoch {epoch}, Batch {e+1}, Average Loss: {np.mean(losses[-100:]):.4f}\")\n",
    "    \n",
    "    batchlosses.append(np.mean(losses[-100:]))\n",
    "    print(f\"Epoch {epoch}, Average Loss: {batchlosses[-1]:.4f}\")\n",
    "    plt.plot(batchlosses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if epoch % 2 == 0 and epoch > 0:\n",
    "        torch.save(model.state_dict(), f\"data_SHAN_CIFAR/DDPM_{epoch}.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a74a6-6786-43c8-9b7b-569eb01df2f2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f69f28-7031-48bc-96d4-85b61ba8d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1410cbf71d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsVklEQVR4nO3df4yV5Z338c99n3PmMMgwSpH5UUZ2tgW7FSWpuAj1B7LLxNlniZZuYmvSQLZrakETQht30T+cbFLGuJHYhJXtdhsWs7L4x6rr82hVusjQhqULPhpZ7GOwYhkr48hUZob5cX7c9/X8wXLSEcTrCzNcM8P7lZyEOec711z3fd3nfM/NOedzIuecEwAAAcShJwAAuHTRhAAAwdCEAADB0IQAAMHQhAAAwdCEAADB0IQAAMHQhAAAwWRDT+CT0jTVBx98oJqaGkVRFHo6AAAj55z6+/vV2NioOD73uc64a0IffPCBmpqaQk8DAHCBOjs7NXv27HPWjFkTeuKJJ/R3f/d3OnbsmK655ho9/vjjuvnmmz/z92pqaiRJ377rO6qqynv9rbRc9p5XYkwpSlzqXWtNQErSxH/s1Dpv//pItjPOz3hic+b4hjPaKLJtp2Xm1rEzhtFj40l7JmP7hVw2411blbUtUM4w+ci49rFhH2aNB1Y26//wlbEukFFqeJxIE9txmFoeJ4yPQbHhFZnYsA+Hi0X94Cc/qjyen8uYNKGnn35a69at0xNPPKGvfvWr+tGPfqTW1la99dZbuuqqq875u6cfsKqq8sp7NqEk9r+DjmkTSv1rJZrQ2WvHURMyzNv6GJcd0ybkXyvZmpB17U1NKEMTOmv9BGxCp/nc98fkjQmbNm3St7/9bf3VX/2V/uiP/kiPP/64mpqatGXLlrH4cwCACWrUm1CxWNRrr72mlpaWEde3tLRo7969Z9QXCgX19fWNuAAALg2j3oSOHz+uJElUV1c34vq6ujp1dXWdUd/e3q7a2trKhTclAMClY8w+J/TJ/wt0zp31/wc3bNig3t7eyqWzs3OspgQAGGdG/Y0JM2fOVCaTOeOsp7u7+4yzI0nK5/PK5/3egAAAmFxG/UyoqqpK119/vXbu3Dni+p07d2rJkiWj/ecAABPYmLxFe/369frWt76lhQsXavHixfrHf/xHHT16VPfee+9Y/DkAwAQ1Jk3orrvuUk9Pj/72b/9Wx44d0/z58/Xiiy9qzpw5Y/HnAAAT1JglJqxZs0Zr1qw5798f7BtWOef3AbCy8/8wl5ztA1epLB9WNX4IzfIBN+MHYS1zMe4SWSP9LJ9xs38i3/ChXOPYlo98Gj9nqdT6Czn/+qrqKtvYhgPAlW3HYdnyYe+M7UO2UZozjG3b39aPZaaGD4mm1scJw33fMg8zw/IMp0XvWlK0AQDB0IQAAMHQhAAAwdCEAADB0IQAAMHQhAAAwdCEAADB0IQAAMHQhAAAwdCEAADBjFlsz4UqDpWksl94hiW2J47HsO8aIzMs5amzzdsUI2KN+jDWR5EhWscQkyRJceRfn4mN62PIJzIuj5wtoUYZyy8YIn4kmZ6KuqRsGjqxRM4Ys3Jc2f/hK2uNBLJmPBnmbr+7GSK4jIOnhtgrQwKTkhKxPQCACYAmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIZtxmx7kklfPMBUtT/+w4GfPDYksmlDFvKo3886xsiV1SYsmbMuR7nfoFY/iVIQ8uMo6dtWTNWZ9yxYZ5W7PgDJldkhQn/vVJwTYXy/rIkNMoGbPMjNlxabnkXVuObQsUZ2wHS2y571sz8gzHSprajquSIRDOkjNXKJIdBwCYAGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYMZtbE+5UFTkmRBSMsTOVFXlTPOIcv5xH3HGOnaVd22xbIvWKQ77x2ZEzvZcxBmiPv7nL4zZXFLDXHLmefvHlMSRLS7FGaNbyiX/uJxhY7RObIlVskT8yJjwZMnIkhTF/sdK7BkBVqk3ziVjmEvGOLYMx5Y1tqeY+B8rliiwQsk/UokzIQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAw4zY7rlQsyTemypJ/FEW2vhtl/HdRrsq2O7P5vHetk38WnCQNlcvetbnIlmVlzdVyhn3uDDmAkvchcmpsQxbc//yCt4xxaOtUyoZjPE1s+zCy5N5ZM/IstcbjULEh2y+27ZOs8RjPGY7xXMb2GGTJJUxNYX1SajmuDKuZpv7jciYEAAhm1JtQW1uboigacamvrx/tPwMAmATG5L/jrrnmGv3sZz+r/JzJ+H8dAgDg0jEmTSibzXL2AwD4TGPymtDhw4fV2Nio5uZmfeMb39C77777qbWFQkF9fX0jLgCAS8OoN6FFixbpySef1Msvv6wf//jH6urq0pIlS9TT03PW+vb2dtXW1lYuTU1Noz0lAMA4NepNqLW1VV//+td17bXX6k//9E/1wgsvSJK2bdt21voNGzaot7e3cuns7BztKQEAxqkx/5zQZZddpmuvvVaHDx8+6+35fF55w+dlAACTx5h/TqhQKOhXv/qVGhoaxvpPAQAmmFFvQt///vfV0dGhI0eO6Je//KX+4i/+Qn19fVq1atVo/ykAwAQ36v8d9/777+ub3/ymjh8/riuvvFI33nij9u3bpzlz5pjGScuJUufXI0sl/4gaF/vXSlLR0KenxrbdWX2Z/9jZfJVp7Mjw2awote2TjDFeJTFEoFjTbyzPo6yRQC7yr0/HMM5Gss09NYUZyRTF45xt7MSwpYkxUsuSlWRM7VHWeIxHWf/7Wy5jjL0y7ENnje1JDVE8lnkYxh31JrRjx47RHhIAMEmRHQcACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACGbMv8rhfMWp5B05lvgHQ5USW7ZSVPYfOx4eNo09pTzVu3bGFZebxq6KDc8vBk+axh4eHDLVFw3ZdIWkaBrbspk5Y75bzpB5lzGObclrO8X/OIwMuV2SlLrEv9aYM2ipjyyLKSkT+ecpOmu2n3EfZjL+c5mSteVApoY8uJJhLf9ndGO9L0Ou3xjNAACAz0QTAgAEQxMCAARDEwIABEMTAgAEQxMCAARDEwIABEMTAgAEQxMCAARDEwIABDN+Y3ucU+wbV2GI2DAkYJxS9v+FgcE+09BpoeBd2zxtimnsz82a7l07dLxkGvvXH35gqi9bYmHKtuij1D9ZR67KFpcS5f3vHlFsiz+ZUp0z1ceG54upMfqoXBz0rq3KmIbWoCESKjbG9tRaoqwMx4kkDQ/boqlyhvWfMs0/rkuSXOy/050zxvBY4okiy53Nv5QzIQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAw4zY7LhdFynlmFZk6qX+M2SmGLKZk0D8LTpL6B/yz5tzJmaaxL591uXftRz3HTWMf/u//a6qvb6z3rs1V2cL93jty1Lv28itt+/CKy6Z5106ttuXSZYds9fkp/llzA4bjSpKqDI8C13/lOtPY/b293rW/7ew0jT1zerV3bfUUW/bi7z6yHYcFQw5kasylyxuOwyRre0gfkH9WYxr575Mo8n/c5EwIABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEMy4zY7LxpFysV92XM4Q81RObZlQUeqfgRTJb76V+tg/D8wVy6axPz72oXfta/91wDR2dVXGVL92zSrv2ivrbflu/+fZ/+1d+/NdHaaxewZPetdOa2o0jX3552zb+bvuj7xr3/uNf56eJLnEPz/s7q8vN42dneOfG3iyx/+YlSRX9J/3lJqpprEvv8yWNdczNOhdO3jihGlsZ3l8y/o/pkhSmvqHaRpiNOXK/uNyJgQACMbchPbs2aMVK1aosbFRURTpueeeG3G7c05tbW1qbGxUdXW1li5dqkOHDo3WfAEAk4i5CQ0MDGjBggXavHnzWW9/9NFHtWnTJm3evFn79+9XfX29li9frv7+/gueLABgcjG/JtTa2qrW1taz3uac0+OPP66HHnpIK1eulCRt27ZNdXV12r59u77zne9c2GwBAJPKqL4mdOTIEXV1damlpaVyXT6f16233qq9e/ee9XcKhYL6+vpGXAAAl4ZRbUJdXV2SpLq6uhHX19XVVW77pPb2dtXW1lYuTU1NozklAMA4Nibvjos+8bXczrkzrjttw4YN6u3trVw6jV/xCwCYuEb1c0L19ac+E9DV1aWGhobK9d3d3WecHZ2Wz+eVz+dHcxoAgAliVM+EmpubVV9fr507d1auKxaL6ujo0JIlS0bzTwEAJgHzmdDJkyf1zjvvVH4+cuSI3njjDc2YMUNXXXWV1q1bp40bN2ru3LmaO3euNm7cqKlTp+ruu+8e1YkDACY+cxM6cOCAbrvttsrP69evlyStWrVK//zP/6wHHnhAQ0NDWrNmjT7++GMtWrRIr7zyimpqakx/pyrKqCr2i4fJGtJyUmtsz6e8lnU2uXy1aeysYe8PDNlie7qP+7+21jc4YBr75q8uMNXfdstXvGuvmN3w2UW/J5v1P5l/6//ZPjQ9Y/rl3rUr7/hfprFra233hz3/4R85dOjNg6axk9Q/cqY4bDtWFBn+s6VcMg1dKvlHw5SHh0xjZz0jw06rMhyH5cSQfyOpbIgnSi0ZP5JiQxZPGvmPHcl/bcxNaOnSpXLn2NAoitTW1qa2tjbr0ACASwzZcQCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYEb1qxxGUzZ2ysZ+WUU5+ec8pVm/PLrTSvKvL5dteVPDZf/cpv7jtm+c/bjnI+/aq2bPNo199Re+aKr/6KNe79rfvN9tGnvgpH+WWa/xW3tzsf9ztD/8Q9s+nN1Qb6r/XJX/151cd/UfmsZOEv9sshlXzDSNvfunP/Ou7em2rU+NIX9vaNB/GyUpNmaw5QxZc4YINklSmvjnsLnIlr+n1DK2/7Au9X9s40wIABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABDM+I3tycbKeUbsZAxJPLEh4keSipF//XBk252pIepjeNgWOxJlct61X/iDz5vGvrx2hqn+12/9xrv2RJ9/xI8kleWfgZIp++8TSZri/KNyPv7ohGnsnt8eN9UfOvjf3rVNcxpNY3/py9d413YdPWoa++gHv/OuTcqmoVWdGO4/Q0XT2BnDcSVJkSHmJ2N7CJKcIVrHGB3mDDvdGfKGLONyJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIZvxmx8WnLj4yhgy2jCH/6BT/sUsZW08vRP71fcO27KtphiyrK2prTWNflrNlsB3/oMe7drBoy8g73tfvXTu1xradV18737t2ULZ9svcXvzTV/8fLr3jX3nzzDaaxpzXM8q79bc8J09gDqf9xmIttD0fF1L82Hi6Zxs5FhsEl5eRfHxseryRJ/tFxSg3zkKRyyT/jzRJLVy6THQcAmABoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGDGbWxPLhMpl/HLiaiK/aNBUmfIwJAUO0NWRabKNLYpYMMYN5TP+sfI5LMZ09iFwYKp/mTP77xrB4ZtsT0fGmJ7Ptc42zR2bcPnvWuP9vSaxv6vQ4dN9R8X/I/b2ivrTWMPpv7H+OH3PzSN3W84yGurbMdhsWzJs7Hdf1JjbI9i//qcNbYn8t9Ol9rOK0pF/zijovz3YZHYHgDAREATAgAEY25Ce/bs0YoVK9TY2KgoivTcc8+NuH316tWKomjE5cYbbxyt+QIAJhFzExoYGNCCBQu0efPmT625/fbbdezYscrlxRdfvKBJAgAmJ/MbE1pbW9Xa2nrOmnw+r/p624ujAIBLz5i8JrR7927NmjVL8+bN0z333KPu7u5PrS0UCurr6xtxAQBcGka9CbW2tuqpp57Srl279Nhjj2n//v1atmyZCoWzv623vb1dtbW1lUtTU9NoTwkAME6N+ueE7rrrrsq/58+fr4ULF2rOnDl64YUXtHLlyjPqN2zYoPXr11d+7uvroxEBwCVizD+s2tDQoDlz5ujw4bN/OC+fzyufz4/1NAAA49CYf06op6dHnZ2damhoGOs/BQCYYMxnQidPntQ777xT+fnIkSN64403NGPGDM2YMUNtbW36+te/roaGBr333nt68MEHNXPmTH3ta18b1YkDACY+cxM6cOCAbrvttsrPp1/PWbVqlbZs2aKDBw/qySef1IkTJ9TQ0KDbbrtNTz/9tGpqakx/Jxc55Tzzm3KG7DhnzY4bLnrXJpF/DpMkxVOmeNdOqbLlTcUl/3kP9dvekTg0xXbYxIZ8qimybWf9jCu8a6fKtvZFw7yPvX3ENPZA/0lT/Rea/HPvZs2oNY197MhR79pfv/1r09gyrGdkzFRLEv98MlPOnCQZs+MiQ33kmYlZYdgv5uy4Yf8cSP9HFKmU+O9vcxNaunSpnPv0B/2XX37ZOiQA4BJFdhwAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIJgx/yqH8xVHTpnILxMuzhmymPzjpiRJhcKg/9A521dSzK5r9K6dNt2WQl443uVde8KYYxYPD5nqqzNV3rXOc80r9Xn/sRPj2F2/9s9U+7jnd6axG2umm+qvvPwy79rh3gHT2L39vd61+cSWqZbL+a9P5hxxYGeTpoY8OEPOnCQVU1u9i/3n4jKmoZUxZMclxuw4V/RPhEvlvz6pITuOMyEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDDjOLbn1MVHVc6/l5YTWzRI0RX8ay0xIpKammZ4186o96+VpIGZ/jEv5Q+7TWOf/O0xU72iknepky0WplzwP4TLWdvh7gzRIzWGeBpJqqm1xfbk5T+Xo2+/Yxq7f6DPu9Y3Suu0rCFyJjLsb0lyhvtbUrbF8KSpf5yNJKXO/xhXZIw+yvrn/CTG84pSwf/xrSz/tSwb4p04EwIABEMTAgAEQxMCAARDEwIABEMTAgAEQxMCAARDEwIABEMTAgAEQxMCAARDEwIABEMTAgAEM26z41IlSj17ZCb1z4XKGvtuNvYfe1retjunTfXPYkrLQ6axhxP/TCgZ88Di2FYfFQ1zMWbHJYl/rlbJmO8WOf/tjCP/tTxVbzsOiyX/4zAt2Y6V1LLLjcdKYsgQSwz3Y0mSpT4xZLtJihNbdpxL/Y/x2HiMR4ZjvGx8fEtM2XH+yoaDijMhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAwNCEAQDA0IQBAMDQhAEAw4za2JykVVHZ+0Q/VceI9bmPTLNM8ps+e4V07nPWP15CkaaVB79p3f/WOaexCyT824/LEf/9J0rTEf96SNKVsiAZJbbEwA7H/Pi8Yt9P0HM3ZYnsk23a6sn+MjCsb428MUTxl2fZh6vzro9QYrZP675M4GTaN7SyxV5Iiw1ycNfrI+T9MJ852XlEq+M+7ZIimKhnux5wJAQCCMTWh9vZ23XDDDaqpqdGsWbN055136u233x5R45xTW1ubGhsbVV1draVLl+rQoUOjOmkAwORgakIdHR1au3at9u3bp507d6pcLqulpUUDAwOVmkcffVSbNm3S5s2btX//ftXX12v58uXq7+8f9ckDACY202tCL7300oift27dqlmzZum1117TLbfcIuecHn/8cT300ENauXKlJGnbtm2qq6vT9u3b9Z3vfGf0Zg4AmPAu6DWh3t5eSdKMGadevD9y5Ii6urrU0tJSqcnn87r11lu1d+/es45RKBTU19c34gIAuDScdxNyzmn9+vW66aabNH/+fElSV1eXJKmurm5EbV1dXeW2T2pvb1dtbW3l0tTUdL5TAgBMMOfdhO677z69+eab+td//dczbos+8VY+59wZ1522YcMG9fb2Vi6dnZ3nOyUAwARzXp8Tuv/++/X8889rz549mj17duX6+vp6SafOiBoaGirXd3d3n3F2dFo+n1c+nz+faQAAJjjTmZBzTvfdd5+eeeYZ7dq1S83NzSNub25uVn19vXbu3Fm5rlgsqqOjQ0uWLBmdGQMAJg3TmdDatWu1fft2/fu//7tqamoqr/PU1taqurpaURRp3bp12rhxo+bOnau5c+dq48aNmjp1qu6+++4x2QAAwMRlakJbtmyRJC1dunTE9Vu3btXq1aslSQ888ICGhoa0Zs0affzxx1q0aJFeeeUV1dTUjMqEAQCTR+ScswUZjbG+vj7V1tbqgcWtymdzXr+TGHKhGuobPrvo95Sqp/jXZmzZcZZ8pQ+O95jGLkf+/9M6rWDLyZrWb3sbfWwYv1z2z7yTpN/F/s+j+szr478PE9nGtrLkqllyzCQpcv5Zc4kx3y2Sf302tR2HOcP9PmPMgoudcS6GfVhljBnMeD4OStKwsx2Hx4f8j5WhjC077uWuPvX29mr69OnnrCU7DgAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQzHl9lcPFEEuGIBT/+JtCf69pHuXCoP/Yn/KdSZ+mVPKP+pgm29iJ/ONvLJEjp+oTY71/NEjJGGmSj/1/IWvch6XEf784Z3s+lzhbPFFsiMvJGPa3deycMf4mY4jiqUr9Y3gkqcowl9gYCRRHtvtE1rD8WcMxK0mxId6r5PwjfiTJGe77LjU8IhvmzJkQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIJjxmx2Xnrp41RqimPIZW2ZX1vnnasmQl3RqbP/6nDH3rJz4b2dszAPLxcasucg/ay42ZN5JUrVhlw9HtvWJUv95lxLb2EnZcFxJcpbsOGNOWtaw/pnElu+WNdRXGedtyTyMY1veYWx8em4pz0S2wWPnf98vGWolKZv475fIsFMiQ54nZ0IAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGBoQgCAYGhCAIBgaEIAgGDGbWxP6lKlzi/CJWeIY5mStfVdZyjPWKNbDBE1ZWMkUDnyH9sZo4wyxqMmzvrP3Rlje7KGOJsphogSSYpT/1iYxDh2qVw01VtieyJjDFNsiMvJJLZ5ZyxxQ4YYHknKyBA5Y7v7KDI+P48NsVpxZIvWiSz1xkigkiFex/LwZqnlTAgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQzLjNjitHkUqemUkZQy+tqq42zcMZMtjisi37yjcbT5LKZWM2WeKfN1U2PhVJjUFcZUMeXFryzxqTpLjsP3aVLZZOkeHeUU6N+XsZ2z607HNjTJosz0UjlzGNbJl3ObVlqllyBk35a5I5gy0T+9dnrdlxsf8+L8u2Pokh2y81HFnOUMuZEAAgGFMTam9v1w033KCamhrNmjVLd955p95+++0RNatXr1YURSMuN95446hOGgAwOZiaUEdHh9auXat9+/Zp586dKpfLamlp0cDAwIi622+/XceOHatcXnzxxVGdNABgcjC9JvTSSy+N+Hnr1q2aNWuWXnvtNd1yyy2V6/P5vOrr60dnhgCASeuCXhPq7e2VJM2YMWPE9bt379asWbM0b9483XPPPeru7v7UMQqFgvr6+kZcAACXhvNuQs45rV+/XjfddJPmz59fub61tVVPPfWUdu3apccee0z79+/XsmXLVCic/dsb29vbVVtbW7k0NTWd75QAABNM5Jyzv6NT0tq1a/XCCy/oF7/4hWbPnv2pdceOHdOcOXO0Y8cOrVy58ozbC4XCiAbV19enpqYmfX/R7cpnc15zmSL/rye+qvFz3rWS7S3a5XH1Fm3D2Mavpk5Ltq941vCQYWzbW7SHDG/RHjK+RbtU8l/PctE276Rsq08Nb6V1xq/gVmL56nDbvGX4yu44tR2HmbF8i3bG+BbtrOEt2hnjW7Sz/m+7HjS+RbvzxKB37VCV/zaWU6f/+GhQvb29mj59+jlrz+tzQvfff7+ef/557dmz55wNSJIaGho0Z84cHT58+Ky35/N55fP585kGAGCCMzUh55zuv/9+Pfvss9q9e7eam5s/83d6enrU2dmphoaG854kAGByMp1zrl27Vv/yL/+i7du3q6amRl1dXerq6tLQ0Kn/bjl58qS+//3v6z//8z/13nvvaffu3VqxYoVmzpypr33ta2OyAQCAict0JrRlyxZJ0tKlS0dcv3XrVq1evVqZTEYHDx7Uk08+qRMnTqihoUG33Xabnn76adXU1IzapAEAk4P5v+POpbq6Wi+//PIFTajytzKxnOeLg4bXppWZasuOsyRxuZL/GyQkSYY3BGRi24u2zjB2mtpeGkwythc/i4YcriRje1E9MbxhI2PMd3OW7bRGkxlfnE4MuWpJ2Th24r8+aWI7VtLU8GYd4/pElvdUmfPabG9MiA3HeM44l4xhbONbUlQ0vKkrMeRRJinZcQCACYAmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACIYmBAAIhiYEAAiGJgQACOa8vsrhYshkc8p4fp+Qk390S1/R9p0/lvQO52w9PTVEAqWG7zWSpCT2j5wpG76XRZISz3WpMMwlrppiG9rwvTzO+H1PseG7jTJZ213JGb9PqGz4Dqe0bJtLueS/ntbvnrLUW6KmpM+OERtZbBpaMkTlSLZonZwx4ylrqC8bHyecpQVY9klEbA8AYAKgCQEAgqEJAQCCoQkBAIKhCQEAgqEJAQCCoQkBAIKhCQEAgqEJAQCCoQkBAIKhCQEAghm32XHZqirlcn6ZVqXUP3Oqd8g/g0uSsln/Pp3J2DKhnCETykX++WuSLWsuMQZrlYz1ZUN5mhrnYojKssxDkiGRUCpHtrUvG7PJiob1Twy5XZJUNhy3ZdmOw7JhLzpjhqEM2XGmnDlJztnWM2N4Pm89DqsMmZQl4z5MY/+sxjhryIBM/efBmRAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIJhxG9uTy8XK5fxiItLUL95HkorG+I5yuexdmzFGfUSxod4cO+Jfnxjig86n3hIkktiGVmKIy0ks+1u2KJ5yxvZ8rpQa428yhhgm6zFuKC8bj/GyYfEN6TSn6g3RMMZdosSYIGQ5ynPG2CvLMW6N1HJV/rE9mSr/eaTE9gAAJgKaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgGJoQACAYmhAAIBiaEAAgmPGbHZc9dfFRMgSOlawhUmniXeoS29iRIW8ssmZCpYbsOEPtqXr/fSJJSeJfX078s/okqVgseteWDDmAklQoGcYuGedtrE8Mc0+M+9CS85UYj3HL2ifGwDZn2E7r2GVjvWX8jLPdf3JZ/5zBOGN7SI+m+mfH5adUedc6w7pzJgQACMbUhLZs2aLrrrtO06dP1/Tp07V48WL99Kc/rdzunFNbW5saGxtVXV2tpUuX6tChQ6M+aQDA5GBqQrNnz9YjjzyiAwcO6MCBA1q2bJnuuOOOSqN59NFHtWnTJm3evFn79+9XfX29li9frv7+/jGZPABgYjM1oRUrVujP/uzPNG/ePM2bN08/+MEPNG3aNO3bt0/OOT3++ON66KGHtHLlSs2fP1/btm3T4OCgtm/fPlbzBwBMYOf9mlCSJNqxY4cGBga0ePFiHTlyRF1dXWppaanU5PN53Xrrrdq7d++njlMoFNTX1zfiAgC4NJib0MGDBzVt2jTl83nde++9evbZZ/XlL39ZXV1dkqS6uroR9XV1dZXbzqa9vV21tbWVS1NTk3VKAIAJytyErr76ar3xxhvat2+fvvvd72rVqlV66623KrdHn/gqWufcGdf9vg0bNqi3t7dy6ezstE4JADBBmT8nVFVVpS9+8YuSpIULF2r//v364Q9/qL/+67+WJHV1damhoaFS393dfcbZ0e/L5/PK5/PWaQAAJoEL/pyQc06FQkHNzc2qr6/Xzp07K7cVi0V1dHRoyZIlF/pnAACTkOlM6MEHH1Rra6uamprU39+vHTt2aPfu3XrppZcURZHWrVunjRs3au7cuZo7d642btyoqVOn6u677x6r+QMAJjBTE/rwww/1rW99S8eOHVNtba2uu+46vfTSS1q+fLkk6YEHHtDQ0JDWrFmjjz/+WIsWLdIrr7yimpoa88SmTJuq6iq/mIhCIec9blIumObhDJFAiSH+RJIiw4moNbZHsaE+Ms7bf5eY6zOGKCNJyhgGTw3xJ5IUW+Yd2+YdR7b1TC31xvWMnWHusXHsnP8+z5RKprGdM9w3y7b9HZdt21m0xCo523Ho5D+X6qztFZbLp0/3rq253L+2WC5L77zjVWua8U9+8pNz3h5Fkdra2tTW1mYZFgBwiSI7DgAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEAxNCAAQDE0IABAMTQgAEIw5RXusOXcqXmO4VPT+nWFD3EepbIwGSfzjOMrW2J5oDGN7DPWps807NW5nkiaGudi2s2SISykZ1lKyRbGUDbWn5uK/TySpbKi31EqyHCrmtbesprOObThuk9R2XFnvy2XLXIzHeGyI7bHO23IcWu4Pp++XzmNbI+dTdRG9//77fLEdAEwCnZ2dmj179jlrxl0TStNUH3zwgWpqakZ8GV5fX5+amprU2dmp6YbQvYmG7Zw8LoVtlNjOyWY0ttM5p/7+fjU2Nir+jHDfcfffcXEcn7NzTp8+fVIfAKexnZPHpbCNEts52VzodtbW1nrV8cYEAEAwNCEAQDATpgnl83k9/PDDyufzoacyptjOyeNS2EaJ7ZxsLvZ2jrs3JgAALh0T5kwIADD50IQAAMHQhAAAwdCEAADBTJgm9MQTT6i5uVlTpkzR9ddfr5///OehpzSq2traFEXRiEt9fX3oaV2QPXv2aMWKFWpsbFQURXruuedG3O6cU1tbmxobG1VdXa2lS5fq0KFDYSZ7AT5rO1evXn3G2t54441hJnue2tvbdcMNN6impkazZs3SnXfeqbfffntEzWRYT5/tnAzruWXLFl133XWVD6QuXrxYP/3pTyu3X8y1nBBN6Omnn9a6dev00EMP6fXXX9fNN9+s1tZWHT16NPTURtU111yjY8eOVS4HDx4MPaULMjAwoAULFmjz5s1nvf3RRx/Vpk2btHnzZu3fv1/19fVavny5+vv7L/JML8xnback3X777SPW9sUXX7yIM7xwHR0dWrt2rfbt26edO3eqXC6rpaVFAwMDlZrJsJ4+2ylN/PWcPXu2HnnkER04cEAHDhzQsmXLdMcdd1QazUVdSzcB/PEf/7G79957R1z3pS99yf3N3/xNoBmNvocfftgtWLAg9DTGjCT37LPPVn5O09TV19e7Rx55pHLd8PCwq62tdf/wD/8QYIaj45Pb6Zxzq1atcnfccUeQ+YyV7u5uJ8l1dHQ45ybven5yO52bnOvpnHNXXHGF+6d/+qeLvpbj/kyoWCzqtddeU0tLy4jrW1patHfv3kCzGhuHDx9WY2Ojmpub9Y1vfEPvvvtu6CmNmSNHjqirq2vEuubzed16662Tbl0laffu3Zo1a5bmzZune+65R93d3aGndEF6e3slSTNmzJA0edfzk9t52mRazyRJtGPHDg0MDGjx4sUXfS3HfRM6fvy4kiRRXV3diOvr6urU1dUVaFajb9GiRXryySf18ssv68c//rG6urq0ZMkS9fT0hJ7amDi9dpN9XSWptbVVTz31lHbt2qXHHntM+/fv17Jly1QoFEJP7bw457R+/XrddNNNmj9/vqTJuZ5n205p8qznwYMHNW3aNOXzed1777169tln9eUvf/mir+W4S9H+NL//tQ7SqQPkk9dNZK2trZV/X3vttVq8eLG+8IUvaNu2bVq/fn3AmY2tyb6uknTXXXdV/j1//nwtXLhQc+bM0QsvvKCVK1cGnNn5ue+++/Tmm2/qF7/4xRm3Tab1/LTtnCzrefXVV+uNN97QiRMn9G//9m9atWqVOjo6KrdfrLUc92dCM2fOVCaTOaMDd3d3n9GpJ5PLLrtM1157rQ4fPhx6KmPi9Dv/LrV1laSGhgbNmTNnQq7t/fffr+eff16vvvrqiK9cmWzr+WnbeTYTdT2rqqr0xS9+UQsXLlR7e7sWLFigH/7whxd9Lcd9E6qqqtL111+vnTt3jrh+586dWrJkSaBZjb1CoaBf/epXamhoCD2VMdHc3Kz6+voR61osFtXR0TGp11WSenp61NnZOaHW1jmn++67T88884x27dql5ubmEbdPlvX8rO08m4m4nmfjnFOhULj4aznqb3UYAzt27HC5XM795Cc/cW+99ZZbt26du+yyy9x7770Xemqj5nvf+57bvXu3e/fdd92+ffvcn//5n7uampoJvY39/f3u9ddfd6+//rqT5DZt2uRef/1195vf/MY559wjjzziamtr3TPPPOMOHjzovvnNb7qGhgbX19cXeOY259rO/v5+973vfc/t3bvXHTlyxL366qtu8eLF7vOf//yE2s7vfve7rra21u3evdsdO3aschkcHKzUTIb1/KztnCzruWHDBrdnzx535MgR9+abb7oHH3zQxXHsXnnlFefcxV3LCdGEnHPu7//+792cOXNcVVWV+8pXvjLiLZOTwV133eUaGhpcLpdzjY2NbuXKle7QoUOhp3VBXn31VSfpjMuqVaucc6fe1vvwww+7+vp6l8/n3S233OIOHjwYdtLn4VzbOTg46FpaWtyVV17pcrmcu+qqq9yqVavc0aNHQ0/b5GzbJ8lt3bq1UjMZ1vOztnOyrOdf/uVfVh5Pr7zySvcnf/InlQbk3MVdS77KAQAQzLh/TQgAMHnRhAAAwdCEAADB0IQAAMHQhAAAwdCEAADB0IQAAMHQhAAAwdCEAADB0IQAAMHQhAAAwdCEAADB/H+34BgIIjoZSQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model = \"DDPM_CIFAR_200.pth\"\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(load_model, map_location=device))\n",
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    batch_size = 1\n",
    "    xt = torch.randn(batch_size, 3, 32, 32).to(device)\n",
    "    \n",
    "\n",
    "    for t in torch.arange(T-1, -1, -1):\n",
    "        t = t.reshape(1)\n",
    "        t = t.to(device)\n",
    "        t_emb = time_embedding_layer(t.float())\n",
    "        z = torch.randn(batch_size, 3, 32, 32).to(device) if t > 1 else torch.zeros(batch_size, 3, 32, 32).to(device)\n",
    "        \n",
    "        xt_new = 1 / torch.sqrt(alpha[t]) * (xt - (1 - alpha[t])/(torch.sqrt(1 - alpha_bar[t])) * \n",
    "                                                    model(xt, t_emb)) + torch.sqrt(beta[t]) * z\n",
    "        xt = xt_new\n",
    "\n",
    "\n",
    "plt.imshow(reverse_transform(xt[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7612842",
   "metadata": {},
   "source": [
    "# Overfit one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from UNET import UNET\n",
    "\n",
    "model = UNET().to(device)\n",
    "# Initialize the linear time embedding layer\n",
    "time_embedding_dim = 128  # You can set this to any suitable size\n",
    "time_embedding_layer = LinearTimeEmbedding(time_embedding_dim).to(device)\n",
    "\n",
    "# Get a single image from the batch\n",
    "single_batch, _ = next(iter(train_loader))\n",
    "single_batch = single_batch[0].unsqueeze(0).to(device)\n",
    "single_batchs = single_batch.repeat(1, 1, 1, 1)\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "plot_every = 400\n",
    "\n",
    "running_loss = 0\n",
    "# Training loop to overfit one batch\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    t = torch.randint(0, T, (1,), device=device)\n",
    "    t_norm = t.float() / T # Normalize the time to [0, 1]\n",
    "    t_emb = time_embedding_layer(t_norm)  # Shape: [1, embedding_dim]\n",
    "    eps = torch.randn_like(single_batchs).to(device)\n",
    "    x_t = torch.sqrt(alpha_bar[t]) * single_batchs + torch.sqrt(1 - alpha_bar[t]) * eps\n",
    "    predicted_eps = model(x_t, t_emb)  # Pass the precomputed embedding to the model\n",
    "    loss = criterion(predicted_eps, eps)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print(f\"Epoch {epoch}, Average Loss: {running_loss / 100:.4f}\")\n",
    "        running_loss = 0.0  \n",
    "\n",
    "    # if epoch % plot_every == 0:\n",
    "    #     with torch.inference_mode():\n",
    "    #         model.eval()\n",
    "    #         t = torch.randint(0, T, (1,), device=device)\n",
    "    #         t_emb = time_embedding_layer(t)\n",
    "    #         eps = torch.randn_like(single_batch).to(device)\n",
    "    #         x_t = torch.sqrt(alpha_bar[t]) * single_batch + torch.sqrt(1 - alpha_bar[t]) * eps\n",
    "    #         predicted_eps = model(x_t, t_emb)\n",
    "    #         reconstructed = x_t - predicted_eps\n",
    "    #         fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
    "    #         axs[0].imshow(predicted_eps[0][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    #         axs[0].set_title(\"Predicted Noise\")\n",
    "    #         axs[1].imshow(eps[0][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    #         axs[1].set_title(\"True Noise\")\n",
    "    #         axs[2].imshow(np.abs(predicted_eps[0][0].cpu().detach().numpy()-eps[0][0].cpu().detach().numpy()), cmap=\"gray\")\n",
    "    #         axs[2].set_title(\"Difference in noise\")\n",
    "    #         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a72823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.826073 0.8980392\n",
      "-29.50021 0.011764705\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a random noise tensor\n",
    "xt = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "# Perform the reverse diffusion process\n",
    "with torch.no_grad():\n",
    "    for t in torch.arange(T-1, -1, -1):\n",
    "        t = t.reshape(1).to(device)\n",
    "        t_emb = time_embedding_layer(t.float())\n",
    "        z = torch.randn(1, 3, 32, 32).to(device) if t > 1 else torch.zeros(1, 3, 32, 32).to(device)\n",
    "        \n",
    "        xt_new = 1 / torch.sqrt(alpha[t]) * (xt - (1 - alpha[t]) / torch.sqrt(1 - alpha_bar[t]) * model(xt, t_emb)) + torch.sqrt(beta[t]) * z\n",
    "        xt = xt_new\n",
    "\n",
    "# Plot the generated image\n",
    "fig,axs = plt.subplots(1, 2, tight_layout=True)\n",
    "im_1 = reverse_transform(xt[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "axs[0].imshow(im_1)\n",
    "axs[0].set_title(\"Generated Image\")\n",
    "axs[0].axis(\"off\")\n",
    "im_2 = reverse_transform(single_batch[0].permute(1, 2, 0).cpu().detach().numpy())\n",
    "axs[1].imshow(im_2)\n",
    "axs[1].set_title(\"Original Image\")\n",
    "axs[1].axis(\"off\")\n",
    "print(im_1.max(),im_2.max())\n",
    "print(im_1.min(),im_2.min())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb7c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
